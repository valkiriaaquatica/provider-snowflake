// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AbortDetachedQueryInitParameters struct {
}

type AbortDetachedQueryObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type AbortDetachedQueryParameters struct {
}

type AutocommitInitParameters struct {
}

type AutocommitObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type AutocommitParameters struct {
}

type BinaryInputFormatInitParameters struct {
}

type BinaryInputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type BinaryInputFormatParameters struct {
}

type BinaryOutputFormatInitParameters struct {
}

type BinaryOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type BinaryOutputFormatParameters struct {
}

type ClientMemoryLimitInitParameters struct {
}

type ClientMemoryLimitObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientMemoryLimitParameters struct {
}

type ClientMetadataRequestUseConnectionCtxInitParameters struct {
}

type ClientMetadataRequestUseConnectionCtxObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientMetadataRequestUseConnectionCtxParameters struct {
}

type ClientPrefetchThreadsInitParameters struct {
}

type ClientPrefetchThreadsObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientPrefetchThreadsParameters struct {
}

type ClientResultChunkSizeInitParameters struct {
}

type ClientResultChunkSizeObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientResultChunkSizeParameters struct {
}

type ClientResultColumnCaseInsensitiveInitParameters struct {
}

type ClientResultColumnCaseInsensitiveObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientResultColumnCaseInsensitiveParameters struct {
}

type ClientSessionKeepAliveHeartbeatFrequencyInitParameters struct {
}

type ClientSessionKeepAliveHeartbeatFrequencyObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientSessionKeepAliveHeartbeatFrequencyParameters struct {
}

type ClientSessionKeepAliveInitParameters struct {
}

type ClientSessionKeepAliveObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientSessionKeepAliveParameters struct {
}

type ClientTimestampTypeMappingInitParameters struct {
}

type ClientTimestampTypeMappingObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ClientTimestampTypeMappingParameters struct {
}

type DateInputFormatInitParameters struct {
}

type DateInputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type DateInputFormatParameters struct {
}

type DateOutputFormatInitParameters struct {
}

type DateOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type DateOutputFormatParameters struct {
}

type EnableUnloadPhysicalTypeOptimizationInitParameters struct {
}

type EnableUnloadPhysicalTypeOptimizationObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type EnableUnloadPhysicalTypeOptimizationParameters struct {
}

type ErrorOnNondeterministicMergeInitParameters struct {
}

type ErrorOnNondeterministicMergeObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ErrorOnNondeterministicMergeParameters struct {
}

type ErrorOnNondeterministicUpdateInitParameters struct {
}

type ErrorOnNondeterministicUpdateObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type ErrorOnNondeterministicUpdateParameters struct {
}

type GeographyOutputFormatInitParameters struct {
}

type GeographyOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type GeographyOutputFormatParameters struct {
}

type GeometryOutputFormatInitParameters struct {
}

type GeometryOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type GeometryOutputFormatParameters struct {
}

type JSONIndentInitParameters struct {
}

type JSONIndentObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type JSONIndentParameters struct {
}

type JdbcTreatTimestampNtzAsUtcInitParameters struct {
}

type JdbcTreatTimestampNtzAsUtcObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type JdbcTreatTimestampNtzAsUtcParameters struct {
}

type JdbcUseSessionTimezoneInitParameters struct {
}

type JdbcUseSessionTimezoneObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type JdbcUseSessionTimezoneParameters struct {
}

type LockTimeoutInitParameters struct {
}

type LockTimeoutObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type LockTimeoutParameters struct {
}

type LogLevelInitParameters struct {
}

type LogLevelObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type LogLevelParameters struct {
}

type MultiStatementCountInitParameters struct {
}

type MultiStatementCountObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type MultiStatementCountParameters struct {
}

type NoorderSequenceAsDefaultInitParameters struct {
}

type NoorderSequenceAsDefaultObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type NoorderSequenceAsDefaultParameters struct {
}

type OdbcTreatDecimalAsIntInitParameters struct {
}

type OdbcTreatDecimalAsIntObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type OdbcTreatDecimalAsIntParameters struct {
}

type ParametersInitParameters struct {
}

type ParametersObservation struct {

	// progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption). For more information, check ABORT_DETACHED_QUERY docs.
	AbortDetachedQuery []AbortDetachedQueryObservation `json:"abortDetachedQuery,omitempty" tf:"abort_detached_query,omitempty"`

	// (Boolean) Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the statement successfully completes. For more information, see Transactions. For more information, check AUTOCOMMIT docs.
	Autocommit []AutocommitObservation `json:"autocommit,omitempty" tf:"autocommit,omitempty"`

	// to-BINARY conversion functions. For more information, see Binary input and output. For more information, check BINARY_INPUT_FORMAT docs.
	BinaryInputFormat []BinaryInputFormatObservation `json:"binaryInputFormat,omitempty" tf:"binary_input_format,omitempty"`

	// to-VARCHAR conversion functions. For more information, see Binary input and output. For more information, check BINARY_OUTPUT_FORMAT docs.
	BinaryOutputFormat []BinaryOutputFormatObservation `json:"binaryOutputFormat,omitempty" tf:"binary_output_format,omitempty"`

	// (Number) Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB). For more information, check CLIENT_MEMORY_LIMIT docs.
	ClientMemoryLimit []ClientMemoryLimitObservation `json:"clientMemoryLimit,omitempty" tf:"client_memory_limit,omitempty"`

	// (Boolean) For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all databases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes more quickly. For more information, check CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX docs.
	ClientMetadataRequestUseConnectionCtx []ClientMetadataRequestUseConnectionCtxObservation `json:"clientMetadataRequestUseConnectionCtx,omitempty" tf:"client_metadata_request_use_connection_ctx,omitempty"`

	// fetch large result sets. The driver will attempt to honor the parameter value, but defines the minimum and maximum values (depending on your system’s resources) to improve performance. For more information, check CLIENT_PREFETCH_THREADS docs.
	ClientPrefetchThreads []ClientPrefetchThreadsObservation `json:"clientPrefetchThreads,omitempty" tf:"client_prefetch_threads,omitempty"`

	// (Number) Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks. For more information, check CLIENT_RESULT_CHUNK_SIZE docs.
	ClientResultChunkSize []ClientResultChunkSizeObservation `json:"clientResultChunkSize,omitempty" tf:"client_result_chunk_size,omitempty"`

	// insensitively in ResultSet.get* methods in JDBC. For more information, check CLIENT_RESULT_COLUMN_CASE_INSENSITIVE docs.
	ClientResultColumnCaseInsensitive []ClientResultColumnCaseInsensitiveObservation `json:"clientResultColumnCaseInsensitive,omitempty" tf:"client_result_column_case_insensitive,omitempty"`

	// (Boolean) Parameter that indicates whether to force a user to log in again after a period of inactivity in the session. For more information, check CLIENT_SESSION_KEEP_ALIVE docs.
	ClientSessionKeepAlive []ClientSessionKeepAliveObservation `json:"clientSessionKeepAlive,omitempty" tf:"client_session_keep_alive,omitempty"`

	// between client attempts to update the token for the session. For more information, check CLIENT_SESSION_KEEP_ALIVE_HEARTBEAT_FREQUENCY docs.
	ClientSessionKeepAliveHeartbeatFrequency []ClientSessionKeepAliveHeartbeatFrequencyObservation `json:"clientSessionKeepAliveHeartbeatFrequency,omitempty" tf:"client_session_keep_alive_heartbeat_frequency,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data. For more information, check CLIENT_TIMESTAMP_TYPE_MAPPING docs.
	ClientTimestampTypeMapping []ClientTimestampTypeMappingObservation `json:"clientTimestampTypeMapping,omitempty" tf:"client_timestamp_type_mapping,omitempty"`

	// (String) Specifies the input format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_INPUT_FORMAT docs.
	DateInputFormat []DateInputFormatObservation `json:"dateInputFormat,omitempty" tf:"date_input_format,omitempty"`

	// (String) Specifies the display format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_OUTPUT_FORMAT docs.
	DateOutputFormat []DateOutputFormatObservation `json:"dateOutputFormat,omitempty" tf:"date_output_format,omitempty"`

	// (Boolean) Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the unloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table). For more information, check ENABLE_UNLOAD_PHYSICAL_TYPE_OPTIMIZATION docs.
	EnableUnloadPhysicalTypeOptimization []EnableUnloadPhysicalTypeOptimizationObservation `json:"enableUnloadPhysicalTypeOptimization,omitempty" tf:"enable_unload_physical_type_optimization,omitempty"`

	// (Boolean) Specifies whether to return an error when the MERGE command is used to update or delete a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_MERGE docs.
	ErrorOnNondeterministicMerge []ErrorOnNondeterministicMergeObservation `json:"errorOnNondeterministicMerge,omitempty" tf:"error_on_nondeterministic_merge,omitempty"`

	// (Boolean) Specifies whether to return an error when the UPDATE command is used to update a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_UPDATE docs.
	ErrorOnNondeterministicUpdate []ErrorOnNondeterministicUpdateObservation `json:"errorOnNondeterministicUpdate,omitempty" tf:"error_on_nondeterministic_update,omitempty"`

	// (String) Display format for GEOGRAPHY values. For more information, check GEOGRAPHY_OUTPUT_FORMAT docs.
	GeographyOutputFormat []GeographyOutputFormatObservation `json:"geographyOutputFormat,omitempty" tf:"geography_output_format,omitempty"`

	// (String) Display format for GEOMETRY values. For more information, check GEOMETRY_OUTPUT_FORMAT docs.
	GeometryOutputFormat []GeometryOutputFormatObservation `json:"geometryOutputFormat,omitempty" tf:"geometry_output_format,omitempty"`

	// (Number) Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element. For more information, check JSON_INDENT docs.
	JSONIndent []JSONIndentObservation `json:"jsonIndent,omitempty" tf:"json_indent,omitempty"`

	// (Boolean) Specifies how JDBC processes TIMESTAMP_NTZ values. For more information, check JDBC_TREAT_TIMESTAMP_NTZ_AS_UTC docs.
	JdbcTreatTimestampNtzAsUtc []JdbcTreatTimestampNtzAsUtcObservation `json:"jdbcTreatTimestampNtzAsUtc,omitempty" tf:"jdbc_treat_timestamp_ntz_as_utc,omitempty"`

	// (Boolean) Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the TIMEZONE parameter) for the getDate(), getTime(), and getTimestamp() methods of the ResultSet class. For more information, check JDBC_USE_SESSION_TIMEZONE docs.
	JdbcUseSessionTimezone []JdbcUseSessionTimezoneObservation `json:"jdbcUseSessionTimezone,omitempty" tf:"jdbc_use_session_timezone,omitempty"`

	// (Number) Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement. For more information, check LOCK_TIMEOUT docs.
	LockTimeout []LockTimeoutObservation `json:"lockTimeout,omitempty" tf:"lock_timeout,omitempty"`

	// (String) Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at the specified level (and at more severe levels) are ingested. For more information about log levels, see Setting log level. For more information, check LOG_LEVEL docs.
	LogLevel []LogLevelObservation `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// statement capability. For more information, check MULTI_STATEMENT_COUNT docs.
	MultiStatementCount []MultiStatementCountObservation `json:"multiStatementCount,omitempty" tf:"multi_statement_count,omitempty"`

	// incremented column in increasing or decreasing order. For more information, check NOORDER_SEQUENCE_AS_DEFAULT docs.
	NoorderSequenceAsDefault []NoorderSequenceAsDefaultObservation `json:"noorderSequenceAsDefault,omitempty" tf:"noorder_sequence_as_default,omitempty"`

	// (Boolean) Specifies how ODBC processes columns that have a scale of zero (0). For more information, check ODBC_TREAT_DECIMAL_AS_INT docs.
	OdbcTreatDecimalAsInt []OdbcTreatDecimalAsIntObservation `json:"odbcTreatDecimalAsInt,omitempty" tf:"odbc_treat_decimal_as_int,omitempty"`

	// (String) Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the QUERY_HISTORY, QUERY_HISTORY_BY_* functions. For more information, check QUERY_TAG docs.
	QueryTag []QueryTagObservation `json:"queryTag,omitempty" tf:"query_tag,omitempty"`

	// quoted object identifiers are stored and resolved as uppercase letters. By default, Snowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers (see Identifier resolution). You can use this parameter in situations in which third-party applications always use double quotes around identifiers. For more information, check QUOTED_IDENTIFIERS_IGNORE_CASE docs.
	QuotedIdentifiersIgnoreCase []QuotedIdentifiersIgnoreCaseObservation `json:"quotedIdentifiersIgnoreCase,omitempty" tf:"quoted_identifiers_ignore_case,omitempty"`

	// (Number) Specifies the maximum number of rows returned in a result set. A value of 0 specifies no maximum. For more information, check ROWS_PER_RESULTSET docs.
	RowsPerResultset []RowsPerResultsetObservation `json:"rowsPerResultset,omitempty" tf:"rows_per_resultset,omitempty"`

	// (String) Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via AWS PrivateLink for Amazon S3 use this endpoint to connect. For more information, see Accessing Internal stages with dedicated interface endpoints. For more information, check S3_STAGE_VPCE_DNS_NAME docs.
	S3StageVpceDNSName []S3StageVpceDNSNameObservation `json:"s3StageVpceDnsName,omitempty" tf:"s3_stage_vpce_dns_name,omitempty"`

	// separated list of identifiers. An identifier can be a fully or partially qualified schema name. For more information, check SEARCH_PATH docs.
	SearchPath []SearchPathObservation `json:"searchPath,omitempty" tf:"search_path,omitempty"`

	// (Number) Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the MAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged. For more information, check STATEMENT_QUEUED_TIMEOUT_IN_SECONDS docs.
	StatementQueuedTimeoutInSeconds []StatementQueuedTimeoutInSecondsObservation `json:"statementQueuedTimeoutInSeconds,omitempty" tf:"statement_queued_timeout_in_seconds,omitempty"`

	// (Number) Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system. For more information, check STATEMENT_TIMEOUT_IN_SECONDS docs.
	StatementTimeoutInSeconds []StatementTimeoutInSecondsObservation `json:"statementTimeoutInSeconds,omitempty" tf:"statement_timeout_in_seconds,omitempty"`

	// standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and languages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON. For more information, check STRICT_JSON_OUTPUT docs.
	StrictJSONOutput []StrictJSONOutputObservation `json:"strictJsonOutput,omitempty" tf:"strict_json_output,omitempty"`

	// (Number) Specifies the number of consecutive failed task runs after which the current task is suspended automatically. The default is 0 (no automatic suspension). For more information, check SUSPEND_TASK_AFTER_NUM_FAILURES docs.
	SuspendTaskAfterNumFailures []SuspendTaskAfterNumFailuresObservation `json:"suspendTaskAfterNumFailures,omitempty" tf:"suspend_task_after_num_failures,omitempty"`

	// (Number) Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically retry the task graphs from the last task in the graph that failed. For more information, check TASK_AUTO_RETRY_ATTEMPTS docs.
	TaskAutoRetryAttempts []TaskAutoRetryAttemptsObservation `json:"taskAutoRetryAttempts,omitempty" tf:"task_auto_retry_attempts,omitempty"`

	// (String) Specifies the input format for the TIME data type. For more information, see Date and time input and output formats. Any valid, supported time format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session). For more information, check TIME_INPUT_FORMAT docs.
	TimeInputFormat []TimeInputFormatObservation `json:"timeInputFormat,omitempty" tf:"time_input_format,omitempty"`

	// (String) Specifies the display format for the TIME data type. For more information, see Date and time input and output formats. For more information, check TIME_OUTPUT_FORMAT docs.
	TimeOutputFormat []TimeOutputFormatObservation `json:"timeOutputFormat,omitempty" tf:"time_output_format,omitempty"`

	// (Boolean) Specifies whether the DATEADD function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days. For more information, check TIMESTAMP_DAY_IS_ALWAYS_24H docs.
	TimestampDayIsAlways24H []TimestampDayIsAlways24HObservation `json:"timestampDayIsAlways24H,omitempty" tf:"timestamp_day_is_always_24h,omitempty"`

	// (String) Specifies the input format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. Any valid, supported timestamp format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session). For more information, check TIMESTAMP_INPUT_FORMAT docs.
	TimestampInputFormat []TimestampInputFormatObservation `json:"timestampInputFormat,omitempty" tf:"timestamp_input_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_LTZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_LTZ_OUTPUT_FORMAT docs.
	TimestampLtzOutputFormat []TimestampLtzOutputFormatObservation `json:"timestampLtzOutputFormat,omitempty" tf:"timestamp_ltz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_NTZ data type. For more information, check TIMESTAMP_NTZ_OUTPUT_FORMAT docs.
	TimestampNtzOutputFormat []TimestampNtzOutputFormatObservation `json:"timestampNtzOutputFormat,omitempty" tf:"timestamp_ntz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_OUTPUT_FORMAT docs.
	TimestampOutputFormat []TimestampOutputFormatObservation `json:"timestampOutputFormat,omitempty" tf:"timestamp_output_format,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to. For more information, check TIMESTAMP_TYPE_MAPPING docs.
	TimestampTypeMapping []TimestampTypeMappingObservation `json:"timestampTypeMapping,omitempty" tf:"timestamp_type_mapping,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_TZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_TZ_OUTPUT_FORMAT docs.
	TimestampTzOutputFormat []TimestampTzOutputFormatObservation `json:"timestampTzOutputFormat,omitempty" tf:"timestamp_tz_output_format,omitempty"`

	// (String) Specifies the time zone for the session. You can specify a time zone name or a link name from release 2021a of the IANA Time Zone Database (e.g. America/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.). For more information, check TIMEZONE docs.
	Timezone []TimezoneObservation `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (String) Controls how trace events are ingested into the event table. For more information about trace levels, see Setting trace level. For more information, check TRACE_LEVEL docs.
	TraceLevel []TraceLevelObservation `json:"traceLevel,omitempty" tf:"trace_level,omitempty"`

	// autocommit transaction returns with an error. For more information, check TRANSACTION_ABORT_ON_ERROR docs.
	TransactionAbortOnError []TransactionAbortOnErrorObservation `json:"transactionAbortOnError,omitempty" tf:"transaction_abort_on_error,omitempty"`

	// (String) Specifies the isolation level for transactions in the user session. For more information, check TRANSACTION_DEFAULT_ISOLATION_LEVEL docs.
	TransactionDefaultIsolationLevel []TransactionDefaultIsolationLevelObservation `json:"transactionDefaultIsolationLevel,omitempty" tf:"transaction_default_isolation_level,omitempty"`

	// digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with the YY date format component (i.e. years represented as 2 digits). For more information, check TWO_DIGIT_CENTURY_START docs.
	TwoDigitCenturyStart []TwoDigitCenturyStartObservation `json:"twoDigitCenturyStart,omitempty" tf:"two_digit_century_start,omitempty"`

	// default) value specified for a constraint property returns an error. For more information, check UNSUPPORTED_DDL_ACTION docs.
	UnsupportedDdlAction []UnsupportedDdlActionObservation `json:"unsupportedDdlAction,omitempty" tf:"unsupported_ddl_action,omitempty"`

	// (Boolean) Specifies whether to reuse persisted query results, if available, when a matching query is submitted. For more information, check USE_CACHED_RESULT docs.
	UseCachedResult []UseCachedResultObservation `json:"useCachedResult,omitempty" tf:"use_cached_result,omitempty"`

	// insensitive): %s. (Conflicts with warehouse). For more information about warehouses, see docs. For more information, check USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE docs.
	UserTaskManagedInitialWarehouseSize []UserTaskManagedInitialWarehouseSizeObservation `json:"userTaskManagedInitialWarehouseSize,omitempty" tf:"user_task_managed_initial_warehouse_size,omitempty"`

	// (Number) Minimum amount of time between Triggered Task executions in seconds For more information, check USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS docs.
	UserTaskMinimumTriggerIntervalInSeconds []UserTaskMinimumTriggerIntervalInSecondsObservation `json:"userTaskMinimumTriggerIntervalInSeconds,omitempty" tf:"user_task_minimum_trigger_interval_in_seconds,omitempty"`

	// (Number) Specifies the time limit on a single run of the task before it times out (in milliseconds). For more information, check USER_TASK_TIMEOUT_MS docs.
	UserTaskTimeoutMs []UserTaskTimeoutMsObservation `json:"userTaskTimeoutMs,omitempty" tf:"user_task_timeout_ms,omitempty"`

	// (Number) Specifies how the weeks in a given year are computed. 0: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year. 1: January 1 is included in the first week of the year and December 31 is included in the last week of the year. For more information, check WEEK_OF_YEAR_POLICY docs.
	WeekOfYearPolicy []WeekOfYearPolicyObservation `json:"weekOfYearPolicy,omitempty" tf:"week_of_year_policy,omitempty"`

	// related date functions). 0: Legacy Snowflake behavior is used (i.e. ISO-like semantics). 1 (Monday) to 7 (Sunday): All the week-related functions use weeks that start on the specified day of the week. For more information, check WEEK_START docs.
	WeekStart []WeekStartObservation `json:"weekStart,omitempty" tf:"week_start,omitempty"`
}

type ParametersParameters struct {
}

type QueryTagInitParameters struct {
}

type QueryTagObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type QueryTagParameters struct {
}

type QuotedIdentifiersIgnoreCaseInitParameters struct {
}

type QuotedIdentifiersIgnoreCaseObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type QuotedIdentifiersIgnoreCaseParameters struct {
}

type RowsPerResultsetInitParameters struct {
}

type RowsPerResultsetObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type RowsPerResultsetParameters struct {
}

type S3StageVpceDNSNameInitParameters struct {
}

type S3StageVpceDNSNameObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type S3StageVpceDNSNameParameters struct {
}

type ScheduleInitParameters struct {

	// (Number) Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only. (conflicts with using_cron)
	// Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only. (conflicts with `using_cron`)
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`

	// (String) Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax. (conflicts with minutes)
	// Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax. (conflicts with `minutes`)
	UsingCron *string `json:"usingCron,omitempty" tf:"using_cron,omitempty"`
}

type ScheduleObservation struct {

	// (Number) Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only. (conflicts with using_cron)
	// Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only. (conflicts with `using_cron`)
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`

	// (String) Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax. (conflicts with minutes)
	// Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax. (conflicts with `minutes`)
	UsingCron *string `json:"usingCron,omitempty" tf:"using_cron,omitempty"`
}

type ScheduleParameters struct {

	// (Number) Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only. (conflicts with using_cron)
	// Specifies an interval (in minutes) of wait time inserted between runs of the task. Accepts positive integers only. (conflicts with `using_cron`)
	// +kubebuilder:validation:Optional
	Minutes *float64 `json:"minutes,omitempty" tf:"minutes,omitempty"`

	// (String) Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax. (conflicts with minutes)
	// Specifies a cron expression and time zone for periodically running the task. Supports a subset of standard cron utility syntax. (conflicts with `minutes`)
	// +kubebuilder:validation:Optional
	UsingCron *string `json:"usingCron,omitempty" tf:"using_cron,omitempty"`
}

type SearchPathInitParameters struct {
}

type SearchPathObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type SearchPathParameters struct {
}

type ShowOutputInitParameters struct {
}

type ShowOutputObservation struct {

	// uses special value that cannot be set in the configuration manually (default)) By default, Snowflake ensures that only one instance of a particular DAG is allowed to run at a time, setting the parameter value to TRUE permits DAG runs to overlap. Available options are: "true" or "false". When the value is not set in the configuration the provider will put "default" there which means to use the Snowflake default for this value.
	AllowOverlappingExecution *bool `json:"allowOverlappingExecution,omitempty" tf:"allow_overlapping_execution,omitempty"`

	// (String)
	Budget *string `json:"budget,omitempty" tf:"budget,omitempty"`

	// (String) Specifies a comment for the task.
	Comment *string `json:"comment,omitempty" tf:"comment,omitempty"`

	// (String)
	Condition *string `json:"condition,omitempty" tf:"condition,omitempty"`

	// (String) Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format.
	Config *string `json:"config,omitempty" tf:"config,omitempty"`

	// (String)
	CreatedOn *string `json:"createdOn,omitempty" tf:"created_on,omitempty"`

	// (String)
	DatabaseName *string `json:"databaseName,omitempty" tf:"database_name,omitempty"`

	// (String)
	Definition *string `json:"definition,omitempty" tf:"definition,omitempty"`

	// (String) Specifies the name of the notification integration used for error notifications. Due to technical limitations (read more here), avoid using the following characters: |, ., ". For more information about this resource, see docs.
	ErrorIntegration *string `json:"errorIntegration,omitempty" tf:"error_integration,omitempty"`

	// (String) The ID of this resource.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// (String)
	LastCommittedOn *string `json:"lastCommittedOn,omitempty" tf:"last_committed_on,omitempty"`

	// (String)
	LastSuspendedOn *string `json:"lastSuspendedOn,omitempty" tf:"last_suspended_on,omitempty"`

	// (String)
	LastSuspendedReason *string `json:"lastSuspendedReason,omitempty" tf:"last_suspended_reason,omitempty"`

	// (String) Specifies the identifier for the task; must be unique for the database and schema in which the task is created. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String)
	Owner *string `json:"owner,omitempty" tf:"owner,omitempty"`

	// (String)
	OwnerRoleType *string `json:"ownerRoleType,omitempty" tf:"owner_role_type,omitempty"`

	// (Set of String)
	// +listType=set
	Predecessors []*string `json:"predecessors,omitempty" tf:"predecessors,omitempty"`

	// fields minutes or using_cron should be set) (see below for nested schema)
	Schedule *string `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// (String)
	SchemaName *string `json:"schemaName,omitempty" tf:"schema_name,omitempty"`

	// (String)
	State *string `json:"state,omitempty" tf:"state,omitempty"`

	// (List of Object) (see below for nested schema)
	TaskRelations []TaskRelationsObservation `json:"taskRelations,omitempty" tf:"task_relations,omitempty"`

	// managed compute resources for runs of this task. Due to Snowflake limitations warehouse identifier can consist of only upper-cased letters. (Conflicts with user_task_managed_initial_warehouse_size) For more information about this resource, see docs.
	Warehouse *string `json:"warehouse,omitempty" tf:"warehouse,omitempty"`
}

type ShowOutputParameters struct {
}

type StatementQueuedTimeoutInSecondsInitParameters struct {
}

type StatementQueuedTimeoutInSecondsObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type StatementQueuedTimeoutInSecondsParameters struct {
}

type StatementTimeoutInSecondsInitParameters struct {
}

type StatementTimeoutInSecondsObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type StatementTimeoutInSecondsParameters struct {
}

type StrictJSONOutputInitParameters struct {
}

type StrictJSONOutputObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type StrictJSONOutputParameters struct {
}

type SuspendTaskAfterNumFailuresInitParameters struct {
}

type SuspendTaskAfterNumFailuresObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type SuspendTaskAfterNumFailuresParameters struct {
}

type TaskAutoRetryAttemptsInitParameters struct {
}

type TaskAutoRetryAttemptsObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TaskAutoRetryAttemptsParameters struct {
}

type TaskInitParameters struct {

	// progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption). For more information, check ABORT_DETACHED_QUERY docs.
	// Specifies the action that Snowflake performs for in-progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption). For more information, check [ABORT_DETACHED_QUERY docs](https://docs.snowflake.com/en/sql-reference/parameters#abort-detached-query).
	AbortDetachedQuery *bool `json:"abortDetachedQuery,omitempty" tf:"abort_detached_query,omitempty"`

	// (Set of String) Specifies one or more predecessor tasks for the current task. Use this option to create a DAG of tasks or add this task to an existing DAG. A DAG is a series of tasks that starts with a scheduled root task and is linked together by dependencies. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies one or more predecessor tasks for the current task. Use this option to [create a DAG](https://docs.snowflake.com/en/user-guide/tasks-graphs.html#label-task-dag) of tasks or add this task to an existing DAG. A DAG is a series of tasks that starts with a scheduled root task and is linked together by dependencies. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	// +listType=set
	After []*string `json:"after,omitempty" tf:"after,omitempty"`

	// uses special value that cannot be set in the configuration manually (default)) By default, Snowflake ensures that only one instance of a particular DAG is allowed to run at a time, setting the parameter value to TRUE permits DAG runs to overlap. Available options are: "true" or "false". When the value is not set in the configuration the provider will put "default" there which means to use the Snowflake default for this value.
	// (Default: fallback to Snowflake default - uses special value that cannot be set in the configuration manually (`default`)) By default, Snowflake ensures that only one instance of a particular DAG is allowed to run at a time, setting the parameter value to TRUE permits DAG runs to overlap. Available options are: "true" or "false". When the value is not set in the configuration the provider will put "default" there which means to use the Snowflake default for this value.
	AllowOverlappingExecution *string `json:"allowOverlappingExecution,omitempty" tf:"allow_overlapping_execution,omitempty"`

	// (Boolean) Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the statement successfully completes. For more information, see Transactions. For more information, check AUTOCOMMIT docs.
	// Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the statement successfully completes. For more information, see [Transactions](https://docs.snowflake.com/en/sql-reference/transactions). For more information, check [AUTOCOMMIT docs](https://docs.snowflake.com/en/sql-reference/parameters#autocommit).
	Autocommit *bool `json:"autocommit,omitempty" tf:"autocommit,omitempty"`

	// to-BINARY conversion functions. For more information, see Binary input and output. For more information, check BINARY_INPUT_FORMAT docs.
	// The format of VARCHAR values passed as input to VARCHAR-to-BINARY conversion functions. For more information, see [Binary input and output](https://docs.snowflake.com/en/sql-reference/binary-input-output). For more information, check [BINARY_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#binary-input-format).
	BinaryInputFormat *string `json:"binaryInputFormat,omitempty" tf:"binary_input_format,omitempty"`

	// to-VARCHAR conversion functions. For more information, see Binary input and output. For more information, check BINARY_OUTPUT_FORMAT docs.
	// The format for VARCHAR values returned as output by BINARY-to-VARCHAR conversion functions. For more information, see [Binary input and output](https://docs.snowflake.com/en/sql-reference/binary-input-output). For more information, check [BINARY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#binary-output-format).
	BinaryOutputFormat *string `json:"binaryOutputFormat,omitempty" tf:"binary_output_format,omitempty"`

	// (Number) Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB). For more information, check CLIENT_MEMORY_LIMIT docs.
	// Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB). For more information, check [CLIENT_MEMORY_LIMIT docs](https://docs.snowflake.com/en/sql-reference/parameters#client-memory-limit).
	ClientMemoryLimit *float64 `json:"clientMemoryLimit,omitempty" tf:"client_memory_limit,omitempty"`

	// (Boolean) For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all databases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes more quickly. For more information, check CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX docs.
	// For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all databases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes more quickly. For more information, check [CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX docs](https://docs.snowflake.com/en/sql-reference/parameters#client-metadata-request-use-connection-ctx).
	ClientMetadataRequestUseConnectionCtx *bool `json:"clientMetadataRequestUseConnectionCtx,omitempty" tf:"client_metadata_request_use_connection_ctx,omitempty"`

	// fetch large result sets. The driver will attempt to honor the parameter value, but defines the minimum and maximum values (depending on your system’s resources) to improve performance. For more information, check CLIENT_PREFETCH_THREADS docs.
	// Parameter that specifies the number of threads used by the client to pre-fetch large result sets. The driver will attempt to honor the parameter value, but defines the minimum and maximum values (depending on your system’s resources) to improve performance. For more information, check [CLIENT_PREFETCH_THREADS docs](https://docs.snowflake.com/en/sql-reference/parameters#client-prefetch-threads).
	ClientPrefetchThreads *float64 `json:"clientPrefetchThreads,omitempty" tf:"client_prefetch_threads,omitempty"`

	// (Number) Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks. For more information, check CLIENT_RESULT_CHUNK_SIZE docs.
	// Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks. For more information, check [CLIENT_RESULT_CHUNK_SIZE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-result-chunk-size).
	ClientResultChunkSize *float64 `json:"clientResultChunkSize,omitempty" tf:"client_result_chunk_size,omitempty"`

	// insensitively in ResultSet.get* methods in JDBC. For more information, check CLIENT_RESULT_COLUMN_CASE_INSENSITIVE docs.
	// Parameter that indicates whether to match column name case-insensitively in ResultSet.get* methods in JDBC. For more information, check [CLIENT_RESULT_COLUMN_CASE_INSENSITIVE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-result-column-case-insensitive).
	ClientResultColumnCaseInsensitive *bool `json:"clientResultColumnCaseInsensitive,omitempty" tf:"client_result_column_case_insensitive,omitempty"`

	// (Boolean) Parameter that indicates whether to force a user to log in again after a period of inactivity in the session. For more information, check CLIENT_SESSION_KEEP_ALIVE docs.
	// Parameter that indicates whether to force a user to log in again after a period of inactivity in the session. For more information, check [CLIENT_SESSION_KEEP_ALIVE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-session-keep-alive).
	ClientSessionKeepAlive *bool `json:"clientSessionKeepAlive,omitempty" tf:"client_session_keep_alive,omitempty"`

	// between client attempts to update the token for the session. For more information, check CLIENT_SESSION_KEEP_ALIVE_HEARTBEAT_FREQUENCY docs.
	// Number of seconds in-between client attempts to update the token for the session. For more information, check [CLIENT_SESSION_KEEP_ALIVE_HEARTBEAT_FREQUENCY docs](https://docs.snowflake.com/en/sql-reference/parameters#client-session-keep-alive-heartbeat-frequency).
	ClientSessionKeepAliveHeartbeatFrequency *float64 `json:"clientSessionKeepAliveHeartbeatFrequency,omitempty" tf:"client_session_keep_alive_heartbeat_frequency,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data. For more information, check CLIENT_TIMESTAMP_TYPE_MAPPING docs.
	// Specifies the [TIMESTAMP_* variation](https://docs.snowflake.com/en/sql-reference/data-types-datetime.html#label-datatypes-timestamp-variations) to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data. For more information, check [CLIENT_TIMESTAMP_TYPE_MAPPING docs](https://docs.snowflake.com/en/sql-reference/parameters#client-timestamp-type-mapping).
	ClientTimestampTypeMapping *string `json:"clientTimestampTypeMapping,omitempty" tf:"client_timestamp_type_mapping,omitempty"`

	// (String) Specifies a comment for the task.
	// Specifies a comment for the task.
	Comment *string `json:"comment,omitempty" tf:"comment,omitempty"`

	// (String) Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format.
	// Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format.
	Config *string `json:"config,omitempty" tf:"config,omitempty"`

	// (String) The database in which to create the task. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// The database in which to create the task. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Database *string `json:"database,omitempty" tf:"database,omitempty"`

	// (String) Specifies the input format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_INPUT_FORMAT docs.
	// Specifies the input format for the DATE data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [DATE_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#date-input-format).
	DateInputFormat *string `json:"dateInputFormat,omitempty" tf:"date_input_format,omitempty"`

	// (String) Specifies the display format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_OUTPUT_FORMAT docs.
	// Specifies the display format for the DATE data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [DATE_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#date-output-format).
	DateOutputFormat *string `json:"dateOutputFormat,omitempty" tf:"date_output_format,omitempty"`

	// (Boolean) Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the unloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table). For more information, check ENABLE_UNLOAD_PHYSICAL_TYPE_OPTIMIZATION docs.
	// Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the unloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table). For more information, check [ENABLE_UNLOAD_PHYSICAL_TYPE_OPTIMIZATION docs](https://docs.snowflake.com/en/sql-reference/parameters#enable-unload-physical-type-optimization).
	EnableUnloadPhysicalTypeOptimization *bool `json:"enableUnloadPhysicalTypeOptimization,omitempty" tf:"enable_unload_physical_type_optimization,omitempty"`

	// (String) Specifies the name of the notification integration used for error notifications. Due to technical limitations (read more here), avoid using the following characters: |, ., ". For more information about this resource, see docs.
	// Specifies the name of the notification integration used for error notifications. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`. For more information about this resource, see [docs](./notification_integration).
	ErrorIntegration *string `json:"errorIntegration,omitempty" tf:"error_integration,omitempty"`

	// (Boolean) Specifies whether to return an error when the MERGE command is used to update or delete a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_MERGE docs.
	// Specifies whether to return an error when the [MERGE](https://docs.snowflake.com/en/sql-reference/sql/merge) command is used to update or delete a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check [ERROR_ON_NONDETERMINISTIC_MERGE docs](https://docs.snowflake.com/en/sql-reference/parameters#error-on-nondeterministic-merge).
	ErrorOnNondeterministicMerge *bool `json:"errorOnNondeterministicMerge,omitempty" tf:"error_on_nondeterministic_merge,omitempty"`

	// (Boolean) Specifies whether to return an error when the UPDATE command is used to update a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_UPDATE docs.
	// Specifies whether to return an error when the [UPDATE](https://docs.snowflake.com/en/sql-reference/sql/update) command is used to update a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check [ERROR_ON_NONDETERMINISTIC_UPDATE docs](https://docs.snowflake.com/en/sql-reference/parameters#error-on-nondeterministic-update).
	ErrorOnNondeterministicUpdate *bool `json:"errorOnNondeterministicUpdate,omitempty" tf:"error_on_nondeterministic_update,omitempty"`

	// (String) Specifies the name of a root task that the finalizer task is associated with. Finalizer tasks run after all other tasks in the task graph run to completion. You can define the SQL of a finalizer task to handle notifications and the release and cleanup of resources that a task graph uses. For more information, see Release and cleanup of task graphs. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies the name of a root task that the finalizer task is associated with. Finalizer tasks run after all other tasks in the task graph run to completion. You can define the SQL of a finalizer task to handle notifications and the release and cleanup of resources that a task graph uses. For more information, see [Release and cleanup of task graphs](https://docs.snowflake.com/en/user-guide/tasks-graphs.html#label-finalizer-task). Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Finalize *string `json:"finalize,omitempty" tf:"finalize,omitempty"`

	// (String) Display format for GEOGRAPHY values. For more information, check GEOGRAPHY_OUTPUT_FORMAT docs.
	// Display format for [GEOGRAPHY values](https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html#label-data-types-geography). For more information, check [GEOGRAPHY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#geography-output-format).
	GeographyOutputFormat *string `json:"geographyOutputFormat,omitempty" tf:"geography_output_format,omitempty"`

	// (String) Display format for GEOMETRY values. For more information, check GEOMETRY_OUTPUT_FORMAT docs.
	// Display format for [GEOMETRY values](https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html#label-data-types-geometry). For more information, check [GEOMETRY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#geometry-output-format).
	GeometryOutputFormat *string `json:"geometryOutputFormat,omitempty" tf:"geometry_output_format,omitempty"`

	// (Number) Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element. For more information, check JSON_INDENT docs.
	// Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element. For more information, check [JSON_INDENT docs](https://docs.snowflake.com/en/sql-reference/parameters#json-indent).
	JSONIndent *float64 `json:"jsonIndent,omitempty" tf:"json_indent,omitempty"`

	// (Boolean) Specifies how JDBC processes TIMESTAMP_NTZ values. For more information, check JDBC_TREAT_TIMESTAMP_NTZ_AS_UTC docs.
	// Specifies how JDBC processes TIMESTAMP_NTZ values. For more information, check [JDBC_TREAT_TIMESTAMP_NTZ_AS_UTC docs](https://docs.snowflake.com/en/sql-reference/parameters#jdbc-treat-timestamp-ntz-as-utc).
	JdbcTreatTimestampNtzAsUtc *bool `json:"jdbcTreatTimestampNtzAsUtc,omitempty" tf:"jdbc_treat_timestamp_ntz_as_utc,omitempty"`

	// (Boolean) Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the TIMEZONE parameter) for the getDate(), getTime(), and getTimestamp() methods of the ResultSet class. For more information, check JDBC_USE_SESSION_TIMEZONE docs.
	// Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the [TIMEZONE](https://docs.snowflake.com/en/sql-reference/parameters#label-timezone) parameter) for the getDate(), getTime(), and getTimestamp() methods of the ResultSet class. For more information, check [JDBC_USE_SESSION_TIMEZONE docs](https://docs.snowflake.com/en/sql-reference/parameters#jdbc-use-session-timezone).
	JdbcUseSessionTimezone *bool `json:"jdbcUseSessionTimezone,omitempty" tf:"jdbc_use_session_timezone,omitempty"`

	// (Number) Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement. For more information, check LOCK_TIMEOUT docs.
	// Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement. For more information, check [LOCK_TIMEOUT docs](https://docs.snowflake.com/en/sql-reference/parameters#lock-timeout).
	LockTimeout *float64 `json:"lockTimeout,omitempty" tf:"lock_timeout,omitempty"`

	// (String) Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at the specified level (and at more severe levels) are ingested. For more information about log levels, see Setting log level. For more information, check LOG_LEVEL docs.
	// Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at the specified level (and at more severe levels) are ingested. For more information about log levels, see [Setting log level](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-log-level). For more information, check [LOG_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#log-level).
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// statement capability. For more information, check MULTI_STATEMENT_COUNT docs.
	// Number of statements to execute when using the multi-statement capability. For more information, check [MULTI_STATEMENT_COUNT docs](https://docs.snowflake.com/en/sql-reference/parameters#multi-statement-count).
	MultiStatementCount *float64 `json:"multiStatementCount,omitempty" tf:"multi_statement_count,omitempty"`

	// (String) Specifies the identifier for the task; must be unique for the database and schema in which the task is created. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies the identifier for the task; must be unique for the database and schema in which the task is created. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// incremented column in increasing or decreasing order. For more information, check NOORDER_SEQUENCE_AS_DEFAULT docs.
	// Specifies whether the ORDER or NOORDER property is set by default when you create a new sequence or add a new table column. The ORDER and NOORDER properties determine whether or not the values are generated for the sequence or auto-incremented column in [increasing or decreasing order](https://docs.snowflake.com/en/user-guide/querying-sequences.html#label-querying-sequences-increasing-values). For more information, check [NOORDER_SEQUENCE_AS_DEFAULT docs](https://docs.snowflake.com/en/sql-reference/parameters#noorder-sequence-as-default).
	NoorderSequenceAsDefault *bool `json:"noorderSequenceAsDefault,omitempty" tf:"noorder_sequence_as_default,omitempty"`

	// (Boolean) Specifies how ODBC processes columns that have a scale of zero (0). For more information, check ODBC_TREAT_DECIMAL_AS_INT docs.
	// Specifies how ODBC processes columns that have a scale of zero (0). For more information, check [ODBC_TREAT_DECIMAL_AS_INT docs](https://docs.snowflake.com/en/sql-reference/parameters#odbc-treat-decimal-as-int).
	OdbcTreatDecimalAsInt *bool `json:"odbcTreatDecimalAsInt,omitempty" tf:"odbc_treat_decimal_as_int,omitempty"`

	// (String) Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the QUERY_HISTORY, QUERY_HISTORY_BY_* functions. For more information, check QUERY_TAG docs.
	// Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the [QUERY_HISTORY, QUERY_HISTORY_BY_*](https://docs.snowflake.com/en/sql-reference/functions/query_history) functions. For more information, check [QUERY_TAG docs](https://docs.snowflake.com/en/sql-reference/parameters#query-tag).
	QueryTag *string `json:"queryTag,omitempty" tf:"query_tag,omitempty"`

	// quoted object identifiers are stored and resolved as uppercase letters. By default, Snowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers (see Identifier resolution). You can use this parameter in situations in which third-party applications always use double quotes around identifiers. For more information, check QUOTED_IDENTIFIERS_IGNORE_CASE docs.
	// Specifies whether letters in double-quoted object identifiers are stored and resolved as uppercase letters. By default, Snowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers (see [Identifier resolution](https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html#label-identifier-casing)). You can use this parameter in situations in which [third-party applications always use double quotes around identifiers](https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html#label-identifier-casing-parameter). For more information, check [QUOTED_IDENTIFIERS_IGNORE_CASE docs](https://docs.snowflake.com/en/sql-reference/parameters#quoted-identifiers-ignore-case).
	QuotedIdentifiersIgnoreCase *bool `json:"quotedIdentifiersIgnoreCase,omitempty" tf:"quoted_identifiers_ignore_case,omitempty"`

	// (Number) Specifies the maximum number of rows returned in a result set. A value of 0 specifies no maximum. For more information, check ROWS_PER_RESULTSET docs.
	// Specifies the maximum number of rows returned in a result set. A value of 0 specifies no maximum. For more information, check [ROWS_PER_RESULTSET docs](https://docs.snowflake.com/en/sql-reference/parameters#rows-per-resultset).
	RowsPerResultset *float64 `json:"rowsPerResultset,omitempty" tf:"rows_per_resultset,omitempty"`

	// (String) Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via AWS PrivateLink for Amazon S3 use this endpoint to connect. For more information, see Accessing Internal stages with dedicated interface endpoints. For more information, check S3_STAGE_VPCE_DNS_NAME docs.
	// Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via [AWS PrivateLink for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html) use this endpoint to connect. For more information, see [Accessing Internal stages with dedicated interface endpoints](https://docs.snowflake.com/en/user-guide/private-internal-stages-aws.html#label-aws-privatelink-internal-stage-network-isolation). For more information, check [S3_STAGE_VPCE_DNS_NAME docs](https://docs.snowflake.com/en/sql-reference/parameters#s3-stage-vpce-dns-name).
	S3StageVpceDNSName *string `json:"s3StageVpceDnsName,omitempty" tf:"s3_stage_vpce_dns_name,omitempty"`

	// (String) Any single SQL statement, or a call to a stored procedure, executed when the task runs.
	// Any single SQL statement, or a call to a stored procedure, executed when the task runs.
	SQLStatement *string `json:"sqlStatement,omitempty" tf:"sql_statement,omitempty"`

	// fields minutes or using_cron should be set) (see below for nested schema)
	// The schedule for periodically running the task. This can be a cron or interval in minutes. (Conflicts with finalize and after; when set, one of the sub-fields `minutes` or `using_cron` should be set)
	Schedule []ScheduleInitParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// (String) The schema in which to create the task. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// The schema in which to create the task. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// separated list of identifiers. An identifier can be a fully or partially qualified schema name. For more information, check SEARCH_PATH docs.
	// Specifies the path to search to resolve unqualified object names in queries. For more information, see [Name resolution in queries](https://docs.snowflake.com/en/sql-reference/name-resolution.html#label-object-name-resolution-search-path). Comma-separated list of identifiers. An identifier can be a fully or partially qualified schema name. For more information, check [SEARCH_PATH docs](https://docs.snowflake.com/en/sql-reference/parameters#search-path).
	SearchPath *string `json:"searchPath,omitempty" tf:"search_path,omitempty"`

	// (Boolean) Specifies if the task should be started or suspended.
	// Specifies if the task should be started or suspended.
	Started *bool `json:"started,omitempty" tf:"started,omitempty"`

	// (Number) Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the MAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged. For more information, check STATEMENT_QUEUED_TIMEOUT_IN_SECONDS docs.
	// Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the [MAX_CONCURRENCY_LEVEL](https://docs.snowflake.com/en/sql-reference/parameters#label-max-concurrency-level) parameter to ensure a warehouse is never backlogged. For more information, check [STATEMENT_QUEUED_TIMEOUT_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#statement-queued-timeout-in-seconds).
	StatementQueuedTimeoutInSeconds *float64 `json:"statementQueuedTimeoutInSeconds,omitempty" tf:"statement_queued_timeout_in_seconds,omitempty"`

	// (Number) Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system. For more information, check STATEMENT_TIMEOUT_IN_SECONDS docs.
	// Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system. For more information, check [STATEMENT_TIMEOUT_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#statement-timeout-in-seconds).
	StatementTimeoutInSeconds *float64 `json:"statementTimeoutInSeconds,omitempty" tf:"statement_timeout_in_seconds,omitempty"`

	// standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and languages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON. For more information, check STRICT_JSON_OUTPUT docs.
	// This parameter specifies whether JSON output in a session is compatible with the general standard (as described by [http://json.org](http://json.org)). By design, Snowflake allows JSON input that contains non-standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and languages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON. For more information, check [STRICT_JSON_OUTPUT docs](https://docs.snowflake.com/en/sql-reference/parameters#strict-json-output).
	StrictJSONOutput *bool `json:"strictJsonOutput,omitempty" tf:"strict_json_output,omitempty"`

	// (Number) Specifies the number of consecutive failed task runs after which the current task is suspended automatically. The default is 0 (no automatic suspension). For more information, check SUSPEND_TASK_AFTER_NUM_FAILURES docs.
	// Specifies the number of consecutive failed task runs after which the current task is suspended automatically. The default is 0 (no automatic suspension). For more information, check [SUSPEND_TASK_AFTER_NUM_FAILURES docs](https://docs.snowflake.com/en/sql-reference/parameters#suspend-task-after-num-failures).
	SuspendTaskAfterNumFailures *float64 `json:"suspendTaskAfterNumFailures,omitempty" tf:"suspend_task_after_num_failures,omitempty"`

	// (Number) Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically retry the task graphs from the last task in the graph that failed. For more information, check TASK_AUTO_RETRY_ATTEMPTS docs.
	// Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically retry the task graphs from the last task in the graph that failed. For more information, check [TASK_AUTO_RETRY_ATTEMPTS docs](https://docs.snowflake.com/en/sql-reference/parameters#task-auto-retry-attempts).
	TaskAutoRetryAttempts *float64 `json:"taskAutoRetryAttempts,omitempty" tf:"task_auto_retry_attempts,omitempty"`

	// (String) Specifies the input format for the TIME data type. For more information, see Date and time input and output formats. Any valid, supported time format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session). For more information, check TIME_INPUT_FORMAT docs.
	// Specifies the input format for the TIME data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). Any valid, supported time format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session). For more information, check [TIME_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#time-input-format).
	TimeInputFormat *string `json:"timeInputFormat,omitempty" tf:"time_input_format,omitempty"`

	// (String) Specifies the display format for the TIME data type. For more information, see Date and time input and output formats. For more information, check TIME_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIME data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIME_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#time-output-format).
	TimeOutputFormat *string `json:"timeOutputFormat,omitempty" tf:"time_output_format,omitempty"`

	// (Boolean) Specifies whether the DATEADD function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days. For more information, check TIMESTAMP_DAY_IS_ALWAYS_24H docs.
	// Specifies whether the [DATEADD](https://docs.snowflake.com/en/sql-reference/functions/dateadd) function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days. For more information, check [TIMESTAMP_DAY_IS_ALWAYS_24H docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-day-is-always-24h).
	TimestampDayIsAlways24H *bool `json:"timestampDayIsAlways24H,omitempty" tf:"timestamp_day_is_always_24h,omitempty"`

	// (String) Specifies the input format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. Any valid, supported timestamp format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session). For more information, check TIMESTAMP_INPUT_FORMAT docs.
	// Specifies the input format for the TIMESTAMP data type alias. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). Any valid, supported timestamp format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session). For more information, check [TIMESTAMP_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-input-format).
	TimestampInputFormat *string `json:"timestampInputFormat,omitempty" tf:"timestamp_input_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_LTZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_LTZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_LTZ data type. If no format is specified, defaults to [TIMESTAMP_OUTPUT_FORMAT](https://docs.snowflake.com/en/sql-reference/parameters#label-timestamp-output-format). For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_LTZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-ltz-output-format).
	TimestampLtzOutputFormat *string `json:"timestampLtzOutputFormat,omitempty" tf:"timestamp_ltz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_NTZ data type. For more information, check TIMESTAMP_NTZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_NTZ data type. For more information, check [TIMESTAMP_NTZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-ntz-output-format).
	TimestampNtzOutputFormat *string `json:"timestampNtzOutputFormat,omitempty" tf:"timestamp_ntz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP data type alias. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-output-format).
	TimestampOutputFormat *string `json:"timestampOutputFormat,omitempty" tf:"timestamp_output_format,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to. For more information, check TIMESTAMP_TYPE_MAPPING docs.
	// Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to. For more information, check [TIMESTAMP_TYPE_MAPPING docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-type-mapping).
	TimestampTypeMapping *string `json:"timestampTypeMapping,omitempty" tf:"timestamp_type_mapping,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_TZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_TZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_TZ data type. If no format is specified, defaults to [TIMESTAMP_OUTPUT_FORMAT](https://docs.snowflake.com/en/sql-reference/parameters#label-timestamp-output-format). For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_TZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-tz-output-format).
	TimestampTzOutputFormat *string `json:"timestampTzOutputFormat,omitempty" tf:"timestamp_tz_output_format,omitempty"`

	// (String) Specifies the time zone for the session. You can specify a time zone name or a link name from release 2021a of the IANA Time Zone Database (e.g. America/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.). For more information, check TIMEZONE docs.
	// Specifies the time zone for the session. You can specify a [time zone name](https://data.iana.org/time-zones/tzdb-2021a/zone1970.tab) or a [link name](https://data.iana.org/time-zones/tzdb-2021a/backward) from release 2021a of the [IANA Time Zone Database](https://www.iana.org/time-zones) (e.g. America/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.). For more information, check [TIMEZONE docs](https://docs.snowflake.com/en/sql-reference/parameters#timezone).
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (String) Controls how trace events are ingested into the event table. For more information about trace levels, see Setting trace level. For more information, check TRACE_LEVEL docs.
	// Controls how trace events are ingested into the event table. For more information about trace levels, see [Setting trace level](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing-trace-level). For more information, check [TRACE_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#trace-level).
	TraceLevel *string `json:"traceLevel,omitempty" tf:"trace_level,omitempty"`

	// autocommit transaction returns with an error. For more information, check TRANSACTION_ABORT_ON_ERROR docs.
	// Specifies the action to perform when a statement issued within a non-autocommit transaction returns with an error. For more information, check [TRANSACTION_ABORT_ON_ERROR docs](https://docs.snowflake.com/en/sql-reference/parameters#transaction-abort-on-error).
	TransactionAbortOnError *bool `json:"transactionAbortOnError,omitempty" tf:"transaction_abort_on_error,omitempty"`

	// (String) Specifies the isolation level for transactions in the user session. For more information, check TRANSACTION_DEFAULT_ISOLATION_LEVEL docs.
	// Specifies the isolation level for transactions in the user session. For more information, check [TRANSACTION_DEFAULT_ISOLATION_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#transaction-default-isolation-level).
	TransactionDefaultIsolationLevel *string `json:"transactionDefaultIsolationLevel,omitempty" tf:"transaction_default_isolation_level,omitempty"`

	// digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with the YY date format component (i.e. years represented as 2 digits). For more information, check TWO_DIGIT_CENTURY_START docs.
	// Specifies the “century start” year for 2-digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with the `YY` date format component (i.e. years represented as 2 digits). For more information, check [TWO_DIGIT_CENTURY_START docs](https://docs.snowflake.com/en/sql-reference/parameters#two-digit-century-start).
	TwoDigitCenturyStart *float64 `json:"twoDigitCenturyStart,omitempty" tf:"two_digit_century_start,omitempty"`

	// default) value specified for a constraint property returns an error. For more information, check UNSUPPORTED_DDL_ACTION docs.
	// Determines if an unsupported (i.e. non-default) value specified for a constraint property returns an error. For more information, check [UNSUPPORTED_DDL_ACTION docs](https://docs.snowflake.com/en/sql-reference/parameters#unsupported-ddl-action).
	UnsupportedDdlAction *string `json:"unsupportedDdlAction,omitempty" tf:"unsupported_ddl_action,omitempty"`

	// (Boolean) Specifies whether to reuse persisted query results, if available, when a matching query is submitted. For more information, check USE_CACHED_RESULT docs.
	// Specifies whether to reuse persisted query results, if available, when a matching query is submitted. For more information, check [USE_CACHED_RESULT docs](https://docs.snowflake.com/en/sql-reference/parameters#use-cached-result).
	UseCachedResult *bool `json:"useCachedResult,omitempty" tf:"use_cached_result,omitempty"`

	// insensitive): %s. (Conflicts with warehouse). For more information about warehouses, see docs. For more information, check USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE docs.
	// Specifies the size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size. Once a task has successfully completed a few runs, Snowflake ignores this parameter setting. Valid values are (case-insensitive): %s. (Conflicts with warehouse). For more information about warehouses, see [docs](./warehouse). For more information, check [USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-managed-initial-warehouse-size).
	UserTaskManagedInitialWarehouseSize *string `json:"userTaskManagedInitialWarehouseSize,omitempty" tf:"user_task_managed_initial_warehouse_size,omitempty"`

	// (Number) Minimum amount of time between Triggered Task executions in seconds For more information, check USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS docs.
	// Minimum amount of time between Triggered Task executions in seconds For more information, check [USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-minimum-trigger-interval-in-seconds).
	UserTaskMinimumTriggerIntervalInSeconds *float64 `json:"userTaskMinimumTriggerIntervalInSeconds,omitempty" tf:"user_task_minimum_trigger_interval_in_seconds,omitempty"`

	// (Number) Specifies the time limit on a single run of the task before it times out (in milliseconds). For more information, check USER_TASK_TIMEOUT_MS docs.
	// Specifies the time limit on a single run of the task before it times out (in milliseconds). For more information, check [USER_TASK_TIMEOUT_MS docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-timeout-ms).
	UserTaskTimeoutMs *float64 `json:"userTaskTimeoutMs,omitempty" tf:"user_task_timeout_ms,omitempty"`

	// managed compute resources for runs of this task. Due to Snowflake limitations warehouse identifier can consist of only upper-cased letters. (Conflicts with user_task_managed_initial_warehouse_size) For more information about this resource, see docs.
	// The warehouse the task will use. Omit this parameter to use Snowflake-managed compute resources for runs of this task. Due to Snowflake limitations warehouse identifier can consist of only upper-cased letters. (Conflicts with user_task_managed_initial_warehouse_size) For more information about this resource, see [docs](./warehouse).
	Warehouse *string `json:"warehouse,omitempty" tf:"warehouse,omitempty"`

	// (Number) Specifies how the weeks in a given year are computed. 0: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year. 1: January 1 is included in the first week of the year and December 31 is included in the last week of the year. For more information, check WEEK_OF_YEAR_POLICY docs.
	// Specifies how the weeks in a given year are computed. `0`: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year. `1`: January 1 is included in the first week of the year and December 31 is included in the last week of the year. For more information, check [WEEK_OF_YEAR_POLICY docs](https://docs.snowflake.com/en/sql-reference/parameters#week-of-year-policy).
	WeekOfYearPolicy *float64 `json:"weekOfYearPolicy,omitempty" tf:"week_of_year_policy,omitempty"`

	// related date functions). 0: Legacy Snowflake behavior is used (i.e. ISO-like semantics). 1 (Monday) to 7 (Sunday): All the week-related functions use weeks that start on the specified day of the week. For more information, check WEEK_START docs.
	// Specifies the first day of the week (used by week-related date functions). `0`: Legacy Snowflake behavior is used (i.e. ISO-like semantics). `1` (Monday) to `7` (Sunday): All the week-related functions use weeks that start on the specified day of the week. For more information, check [WEEK_START docs](https://docs.snowflake.com/en/sql-reference/parameters#week-start).
	WeekStart *float64 `json:"weekStart,omitempty" tf:"week_start,omitempty"`

	// (String) Specifies a Boolean SQL expression; multiple conditions joined with AND/OR are supported. When a task is triggered (based on its SCHEDULE or AFTER setting), it validates the conditions of the expression to determine whether to execute. If the conditions of the expression are not met, then the task skips the current run. Any tasks that identify this task as a predecessor also don’t run.
	// Specifies a Boolean SQL expression; multiple conditions joined with AND/OR are supported. When a task is triggered (based on its SCHEDULE or AFTER setting), it validates the conditions of the expression to determine whether to execute. If the conditions of the expression are not met, then the task skips the current run. Any tasks that identify this task as a predecessor also don’t run.
	When *string `json:"when,omitempty" tf:"when,omitempty"`
}

type TaskObservation struct {

	// progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption). For more information, check ABORT_DETACHED_QUERY docs.
	// Specifies the action that Snowflake performs for in-progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption). For more information, check [ABORT_DETACHED_QUERY docs](https://docs.snowflake.com/en/sql-reference/parameters#abort-detached-query).
	AbortDetachedQuery *bool `json:"abortDetachedQuery,omitempty" tf:"abort_detached_query,omitempty"`

	// (Set of String) Specifies one or more predecessor tasks for the current task. Use this option to create a DAG of tasks or add this task to an existing DAG. A DAG is a series of tasks that starts with a scheduled root task and is linked together by dependencies. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies one or more predecessor tasks for the current task. Use this option to [create a DAG](https://docs.snowflake.com/en/user-guide/tasks-graphs.html#label-task-dag) of tasks or add this task to an existing DAG. A DAG is a series of tasks that starts with a scheduled root task and is linked together by dependencies. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	// +listType=set
	After []*string `json:"after,omitempty" tf:"after,omitempty"`

	// uses special value that cannot be set in the configuration manually (default)) By default, Snowflake ensures that only one instance of a particular DAG is allowed to run at a time, setting the parameter value to TRUE permits DAG runs to overlap. Available options are: "true" or "false". When the value is not set in the configuration the provider will put "default" there which means to use the Snowflake default for this value.
	// (Default: fallback to Snowflake default - uses special value that cannot be set in the configuration manually (`default`)) By default, Snowflake ensures that only one instance of a particular DAG is allowed to run at a time, setting the parameter value to TRUE permits DAG runs to overlap. Available options are: "true" or "false". When the value is not set in the configuration the provider will put "default" there which means to use the Snowflake default for this value.
	AllowOverlappingExecution *string `json:"allowOverlappingExecution,omitempty" tf:"allow_overlapping_execution,omitempty"`

	// (Boolean) Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the statement successfully completes. For more information, see Transactions. For more information, check AUTOCOMMIT docs.
	// Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the statement successfully completes. For more information, see [Transactions](https://docs.snowflake.com/en/sql-reference/transactions). For more information, check [AUTOCOMMIT docs](https://docs.snowflake.com/en/sql-reference/parameters#autocommit).
	Autocommit *bool `json:"autocommit,omitempty" tf:"autocommit,omitempty"`

	// to-BINARY conversion functions. For more information, see Binary input and output. For more information, check BINARY_INPUT_FORMAT docs.
	// The format of VARCHAR values passed as input to VARCHAR-to-BINARY conversion functions. For more information, see [Binary input and output](https://docs.snowflake.com/en/sql-reference/binary-input-output). For more information, check [BINARY_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#binary-input-format).
	BinaryInputFormat *string `json:"binaryInputFormat,omitempty" tf:"binary_input_format,omitempty"`

	// to-VARCHAR conversion functions. For more information, see Binary input and output. For more information, check BINARY_OUTPUT_FORMAT docs.
	// The format for VARCHAR values returned as output by BINARY-to-VARCHAR conversion functions. For more information, see [Binary input and output](https://docs.snowflake.com/en/sql-reference/binary-input-output). For more information, check [BINARY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#binary-output-format).
	BinaryOutputFormat *string `json:"binaryOutputFormat,omitempty" tf:"binary_output_format,omitempty"`

	// (Number) Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB). For more information, check CLIENT_MEMORY_LIMIT docs.
	// Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB). For more information, check [CLIENT_MEMORY_LIMIT docs](https://docs.snowflake.com/en/sql-reference/parameters#client-memory-limit).
	ClientMemoryLimit *float64 `json:"clientMemoryLimit,omitempty" tf:"client_memory_limit,omitempty"`

	// (Boolean) For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all databases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes more quickly. For more information, check CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX docs.
	// For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all databases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes more quickly. For more information, check [CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX docs](https://docs.snowflake.com/en/sql-reference/parameters#client-metadata-request-use-connection-ctx).
	ClientMetadataRequestUseConnectionCtx *bool `json:"clientMetadataRequestUseConnectionCtx,omitempty" tf:"client_metadata_request_use_connection_ctx,omitempty"`

	// fetch large result sets. The driver will attempt to honor the parameter value, but defines the minimum and maximum values (depending on your system’s resources) to improve performance. For more information, check CLIENT_PREFETCH_THREADS docs.
	// Parameter that specifies the number of threads used by the client to pre-fetch large result sets. The driver will attempt to honor the parameter value, but defines the minimum and maximum values (depending on your system’s resources) to improve performance. For more information, check [CLIENT_PREFETCH_THREADS docs](https://docs.snowflake.com/en/sql-reference/parameters#client-prefetch-threads).
	ClientPrefetchThreads *float64 `json:"clientPrefetchThreads,omitempty" tf:"client_prefetch_threads,omitempty"`

	// (Number) Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks. For more information, check CLIENT_RESULT_CHUNK_SIZE docs.
	// Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks. For more information, check [CLIENT_RESULT_CHUNK_SIZE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-result-chunk-size).
	ClientResultChunkSize *float64 `json:"clientResultChunkSize,omitempty" tf:"client_result_chunk_size,omitempty"`

	// insensitively in ResultSet.get* methods in JDBC. For more information, check CLIENT_RESULT_COLUMN_CASE_INSENSITIVE docs.
	// Parameter that indicates whether to match column name case-insensitively in ResultSet.get* methods in JDBC. For more information, check [CLIENT_RESULT_COLUMN_CASE_INSENSITIVE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-result-column-case-insensitive).
	ClientResultColumnCaseInsensitive *bool `json:"clientResultColumnCaseInsensitive,omitempty" tf:"client_result_column_case_insensitive,omitempty"`

	// (Boolean) Parameter that indicates whether to force a user to log in again after a period of inactivity in the session. For more information, check CLIENT_SESSION_KEEP_ALIVE docs.
	// Parameter that indicates whether to force a user to log in again after a period of inactivity in the session. For more information, check [CLIENT_SESSION_KEEP_ALIVE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-session-keep-alive).
	ClientSessionKeepAlive *bool `json:"clientSessionKeepAlive,omitempty" tf:"client_session_keep_alive,omitempty"`

	// between client attempts to update the token for the session. For more information, check CLIENT_SESSION_KEEP_ALIVE_HEARTBEAT_FREQUENCY docs.
	// Number of seconds in-between client attempts to update the token for the session. For more information, check [CLIENT_SESSION_KEEP_ALIVE_HEARTBEAT_FREQUENCY docs](https://docs.snowflake.com/en/sql-reference/parameters#client-session-keep-alive-heartbeat-frequency).
	ClientSessionKeepAliveHeartbeatFrequency *float64 `json:"clientSessionKeepAliveHeartbeatFrequency,omitempty" tf:"client_session_keep_alive_heartbeat_frequency,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data. For more information, check CLIENT_TIMESTAMP_TYPE_MAPPING docs.
	// Specifies the [TIMESTAMP_* variation](https://docs.snowflake.com/en/sql-reference/data-types-datetime.html#label-datatypes-timestamp-variations) to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data. For more information, check [CLIENT_TIMESTAMP_TYPE_MAPPING docs](https://docs.snowflake.com/en/sql-reference/parameters#client-timestamp-type-mapping).
	ClientTimestampTypeMapping *string `json:"clientTimestampTypeMapping,omitempty" tf:"client_timestamp_type_mapping,omitempty"`

	// (String) Specifies a comment for the task.
	// Specifies a comment for the task.
	Comment *string `json:"comment,omitempty" tf:"comment,omitempty"`

	// (String) Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format.
	// Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format.
	Config *string `json:"config,omitempty" tf:"config,omitempty"`

	// (String) The database in which to create the task. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// The database in which to create the task. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Database *string `json:"database,omitempty" tf:"database,omitempty"`

	// (String) Specifies the input format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_INPUT_FORMAT docs.
	// Specifies the input format for the DATE data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [DATE_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#date-input-format).
	DateInputFormat *string `json:"dateInputFormat,omitempty" tf:"date_input_format,omitempty"`

	// (String) Specifies the display format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_OUTPUT_FORMAT docs.
	// Specifies the display format for the DATE data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [DATE_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#date-output-format).
	DateOutputFormat *string `json:"dateOutputFormat,omitempty" tf:"date_output_format,omitempty"`

	// (Boolean) Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the unloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table). For more information, check ENABLE_UNLOAD_PHYSICAL_TYPE_OPTIMIZATION docs.
	// Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the unloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table). For more information, check [ENABLE_UNLOAD_PHYSICAL_TYPE_OPTIMIZATION docs](https://docs.snowflake.com/en/sql-reference/parameters#enable-unload-physical-type-optimization).
	EnableUnloadPhysicalTypeOptimization *bool `json:"enableUnloadPhysicalTypeOptimization,omitempty" tf:"enable_unload_physical_type_optimization,omitempty"`

	// (String) Specifies the name of the notification integration used for error notifications. Due to technical limitations (read more here), avoid using the following characters: |, ., ". For more information about this resource, see docs.
	// Specifies the name of the notification integration used for error notifications. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`. For more information about this resource, see [docs](./notification_integration).
	ErrorIntegration *string `json:"errorIntegration,omitempty" tf:"error_integration,omitempty"`

	// (Boolean) Specifies whether to return an error when the MERGE command is used to update or delete a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_MERGE docs.
	// Specifies whether to return an error when the [MERGE](https://docs.snowflake.com/en/sql-reference/sql/merge) command is used to update or delete a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check [ERROR_ON_NONDETERMINISTIC_MERGE docs](https://docs.snowflake.com/en/sql-reference/parameters#error-on-nondeterministic-merge).
	ErrorOnNondeterministicMerge *bool `json:"errorOnNondeterministicMerge,omitempty" tf:"error_on_nondeterministic_merge,omitempty"`

	// (Boolean) Specifies whether to return an error when the UPDATE command is used to update a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_UPDATE docs.
	// Specifies whether to return an error when the [UPDATE](https://docs.snowflake.com/en/sql-reference/sql/update) command is used to update a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check [ERROR_ON_NONDETERMINISTIC_UPDATE docs](https://docs.snowflake.com/en/sql-reference/parameters#error-on-nondeterministic-update).
	ErrorOnNondeterministicUpdate *bool `json:"errorOnNondeterministicUpdate,omitempty" tf:"error_on_nondeterministic_update,omitempty"`

	// (String) Specifies the name of a root task that the finalizer task is associated with. Finalizer tasks run after all other tasks in the task graph run to completion. You can define the SQL of a finalizer task to handle notifications and the release and cleanup of resources that a task graph uses. For more information, see Release and cleanup of task graphs. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies the name of a root task that the finalizer task is associated with. Finalizer tasks run after all other tasks in the task graph run to completion. You can define the SQL of a finalizer task to handle notifications and the release and cleanup of resources that a task graph uses. For more information, see [Release and cleanup of task graphs](https://docs.snowflake.com/en/user-guide/tasks-graphs.html#label-finalizer-task). Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Finalize *string `json:"finalize,omitempty" tf:"finalize,omitempty"`

	// (String) Fully qualified name of the resource. For more information, see object name resolution.
	// Fully qualified name of the resource. For more information, see [object name resolution](https://docs.snowflake.com/en/sql-reference/name-resolution).
	FullyQualifiedName *string `json:"fullyQualifiedName,omitempty" tf:"fully_qualified_name,omitempty"`

	// (String) Display format for GEOGRAPHY values. For more information, check GEOGRAPHY_OUTPUT_FORMAT docs.
	// Display format for [GEOGRAPHY values](https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html#label-data-types-geography). For more information, check [GEOGRAPHY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#geography-output-format).
	GeographyOutputFormat *string `json:"geographyOutputFormat,omitempty" tf:"geography_output_format,omitempty"`

	// (String) Display format for GEOMETRY values. For more information, check GEOMETRY_OUTPUT_FORMAT docs.
	// Display format for [GEOMETRY values](https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html#label-data-types-geometry). For more information, check [GEOMETRY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#geometry-output-format).
	GeometryOutputFormat *string `json:"geometryOutputFormat,omitempty" tf:"geometry_output_format,omitempty"`

	// (String) The ID of this resource.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// (Number) Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element. For more information, check JSON_INDENT docs.
	// Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element. For more information, check [JSON_INDENT docs](https://docs.snowflake.com/en/sql-reference/parameters#json-indent).
	JSONIndent *float64 `json:"jsonIndent,omitempty" tf:"json_indent,omitempty"`

	// (Boolean) Specifies how JDBC processes TIMESTAMP_NTZ values. For more information, check JDBC_TREAT_TIMESTAMP_NTZ_AS_UTC docs.
	// Specifies how JDBC processes TIMESTAMP_NTZ values. For more information, check [JDBC_TREAT_TIMESTAMP_NTZ_AS_UTC docs](https://docs.snowflake.com/en/sql-reference/parameters#jdbc-treat-timestamp-ntz-as-utc).
	JdbcTreatTimestampNtzAsUtc *bool `json:"jdbcTreatTimestampNtzAsUtc,omitempty" tf:"jdbc_treat_timestamp_ntz_as_utc,omitempty"`

	// (Boolean) Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the TIMEZONE parameter) for the getDate(), getTime(), and getTimestamp() methods of the ResultSet class. For more information, check JDBC_USE_SESSION_TIMEZONE docs.
	// Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the [TIMEZONE](https://docs.snowflake.com/en/sql-reference/parameters#label-timezone) parameter) for the getDate(), getTime(), and getTimestamp() methods of the ResultSet class. For more information, check [JDBC_USE_SESSION_TIMEZONE docs](https://docs.snowflake.com/en/sql-reference/parameters#jdbc-use-session-timezone).
	JdbcUseSessionTimezone *bool `json:"jdbcUseSessionTimezone,omitempty" tf:"jdbc_use_session_timezone,omitempty"`

	// (Number) Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement. For more information, check LOCK_TIMEOUT docs.
	// Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement. For more information, check [LOCK_TIMEOUT docs](https://docs.snowflake.com/en/sql-reference/parameters#lock-timeout).
	LockTimeout *float64 `json:"lockTimeout,omitempty" tf:"lock_timeout,omitempty"`

	// (String) Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at the specified level (and at more severe levels) are ingested. For more information about log levels, see Setting log level. For more information, check LOG_LEVEL docs.
	// Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at the specified level (and at more severe levels) are ingested. For more information about log levels, see [Setting log level](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-log-level). For more information, check [LOG_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#log-level).
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// statement capability. For more information, check MULTI_STATEMENT_COUNT docs.
	// Number of statements to execute when using the multi-statement capability. For more information, check [MULTI_STATEMENT_COUNT docs](https://docs.snowflake.com/en/sql-reference/parameters#multi-statement-count).
	MultiStatementCount *float64 `json:"multiStatementCount,omitempty" tf:"multi_statement_count,omitempty"`

	// (String) Specifies the identifier for the task; must be unique for the database and schema in which the task is created. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies the identifier for the task; must be unique for the database and schema in which the task is created. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// incremented column in increasing or decreasing order. For more information, check NOORDER_SEQUENCE_AS_DEFAULT docs.
	// Specifies whether the ORDER or NOORDER property is set by default when you create a new sequence or add a new table column. The ORDER and NOORDER properties determine whether or not the values are generated for the sequence or auto-incremented column in [increasing or decreasing order](https://docs.snowflake.com/en/user-guide/querying-sequences.html#label-querying-sequences-increasing-values). For more information, check [NOORDER_SEQUENCE_AS_DEFAULT docs](https://docs.snowflake.com/en/sql-reference/parameters#noorder-sequence-as-default).
	NoorderSequenceAsDefault *bool `json:"noorderSequenceAsDefault,omitempty" tf:"noorder_sequence_as_default,omitempty"`

	// (Boolean) Specifies how ODBC processes columns that have a scale of zero (0). For more information, check ODBC_TREAT_DECIMAL_AS_INT docs.
	// Specifies how ODBC processes columns that have a scale of zero (0). For more information, check [ODBC_TREAT_DECIMAL_AS_INT docs](https://docs.snowflake.com/en/sql-reference/parameters#odbc-treat-decimal-as-int).
	OdbcTreatDecimalAsInt *bool `json:"odbcTreatDecimalAsInt,omitempty" tf:"odbc_treat_decimal_as_int,omitempty"`

	// (List of Object) Outputs the result of SHOW PARAMETERS IN TASK for the given task. (see below for nested schema)
	// Outputs the result of `SHOW PARAMETERS IN TASK` for the given task.
	Parameters []ParametersObservation `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// (String) Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the QUERY_HISTORY, QUERY_HISTORY_BY_* functions. For more information, check QUERY_TAG docs.
	// Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the [QUERY_HISTORY, QUERY_HISTORY_BY_*](https://docs.snowflake.com/en/sql-reference/functions/query_history) functions. For more information, check [QUERY_TAG docs](https://docs.snowflake.com/en/sql-reference/parameters#query-tag).
	QueryTag *string `json:"queryTag,omitempty" tf:"query_tag,omitempty"`

	// quoted object identifiers are stored and resolved as uppercase letters. By default, Snowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers (see Identifier resolution). You can use this parameter in situations in which third-party applications always use double quotes around identifiers. For more information, check QUOTED_IDENTIFIERS_IGNORE_CASE docs.
	// Specifies whether letters in double-quoted object identifiers are stored and resolved as uppercase letters. By default, Snowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers (see [Identifier resolution](https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html#label-identifier-casing)). You can use this parameter in situations in which [third-party applications always use double quotes around identifiers](https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html#label-identifier-casing-parameter). For more information, check [QUOTED_IDENTIFIERS_IGNORE_CASE docs](https://docs.snowflake.com/en/sql-reference/parameters#quoted-identifiers-ignore-case).
	QuotedIdentifiersIgnoreCase *bool `json:"quotedIdentifiersIgnoreCase,omitempty" tf:"quoted_identifiers_ignore_case,omitempty"`

	// (Number) Specifies the maximum number of rows returned in a result set. A value of 0 specifies no maximum. For more information, check ROWS_PER_RESULTSET docs.
	// Specifies the maximum number of rows returned in a result set. A value of 0 specifies no maximum. For more information, check [ROWS_PER_RESULTSET docs](https://docs.snowflake.com/en/sql-reference/parameters#rows-per-resultset).
	RowsPerResultset *float64 `json:"rowsPerResultset,omitempty" tf:"rows_per_resultset,omitempty"`

	// (String) Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via AWS PrivateLink for Amazon S3 use this endpoint to connect. For more information, see Accessing Internal stages with dedicated interface endpoints. For more information, check S3_STAGE_VPCE_DNS_NAME docs.
	// Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via [AWS PrivateLink for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html) use this endpoint to connect. For more information, see [Accessing Internal stages with dedicated interface endpoints](https://docs.snowflake.com/en/user-guide/private-internal-stages-aws.html#label-aws-privatelink-internal-stage-network-isolation). For more information, check [S3_STAGE_VPCE_DNS_NAME docs](https://docs.snowflake.com/en/sql-reference/parameters#s3-stage-vpce-dns-name).
	S3StageVpceDNSName *string `json:"s3StageVpceDnsName,omitempty" tf:"s3_stage_vpce_dns_name,omitempty"`

	// (String) Any single SQL statement, or a call to a stored procedure, executed when the task runs.
	// Any single SQL statement, or a call to a stored procedure, executed when the task runs.
	SQLStatement *string `json:"sqlStatement,omitempty" tf:"sql_statement,omitempty"`

	// fields minutes or using_cron should be set) (see below for nested schema)
	// The schedule for periodically running the task. This can be a cron or interval in minutes. (Conflicts with finalize and after; when set, one of the sub-fields `minutes` or `using_cron` should be set)
	Schedule []ScheduleObservation `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// (String) The schema in which to create the task. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// The schema in which to create the task. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// separated list of identifiers. An identifier can be a fully or partially qualified schema name. For more information, check SEARCH_PATH docs.
	// Specifies the path to search to resolve unqualified object names in queries. For more information, see [Name resolution in queries](https://docs.snowflake.com/en/sql-reference/name-resolution.html#label-object-name-resolution-search-path). Comma-separated list of identifiers. An identifier can be a fully or partially qualified schema name. For more information, check [SEARCH_PATH docs](https://docs.snowflake.com/en/sql-reference/parameters#search-path).
	SearchPath *string `json:"searchPath,omitempty" tf:"search_path,omitempty"`

	// (List of Object) Outputs the result of SHOW TASKS for the given task. (see below for nested schema)
	// Outputs the result of `SHOW TASKS` for the given task.
	ShowOutput []ShowOutputObservation `json:"showOutput,omitempty" tf:"show_output,omitempty"`

	// (Boolean) Specifies if the task should be started or suspended.
	// Specifies if the task should be started or suspended.
	Started *bool `json:"started,omitempty" tf:"started,omitempty"`

	// (Number) Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the MAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged. For more information, check STATEMENT_QUEUED_TIMEOUT_IN_SECONDS docs.
	// Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the [MAX_CONCURRENCY_LEVEL](https://docs.snowflake.com/en/sql-reference/parameters#label-max-concurrency-level) parameter to ensure a warehouse is never backlogged. For more information, check [STATEMENT_QUEUED_TIMEOUT_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#statement-queued-timeout-in-seconds).
	StatementQueuedTimeoutInSeconds *float64 `json:"statementQueuedTimeoutInSeconds,omitempty" tf:"statement_queued_timeout_in_seconds,omitempty"`

	// (Number) Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system. For more information, check STATEMENT_TIMEOUT_IN_SECONDS docs.
	// Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system. For more information, check [STATEMENT_TIMEOUT_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#statement-timeout-in-seconds).
	StatementTimeoutInSeconds *float64 `json:"statementTimeoutInSeconds,omitempty" tf:"statement_timeout_in_seconds,omitempty"`

	// standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and languages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON. For more information, check STRICT_JSON_OUTPUT docs.
	// This parameter specifies whether JSON output in a session is compatible with the general standard (as described by [http://json.org](http://json.org)). By design, Snowflake allows JSON input that contains non-standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and languages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON. For more information, check [STRICT_JSON_OUTPUT docs](https://docs.snowflake.com/en/sql-reference/parameters#strict-json-output).
	StrictJSONOutput *bool `json:"strictJsonOutput,omitempty" tf:"strict_json_output,omitempty"`

	// (Number) Specifies the number of consecutive failed task runs after which the current task is suspended automatically. The default is 0 (no automatic suspension). For more information, check SUSPEND_TASK_AFTER_NUM_FAILURES docs.
	// Specifies the number of consecutive failed task runs after which the current task is suspended automatically. The default is 0 (no automatic suspension). For more information, check [SUSPEND_TASK_AFTER_NUM_FAILURES docs](https://docs.snowflake.com/en/sql-reference/parameters#suspend-task-after-num-failures).
	SuspendTaskAfterNumFailures *float64 `json:"suspendTaskAfterNumFailures,omitempty" tf:"suspend_task_after_num_failures,omitempty"`

	// (Number) Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically retry the task graphs from the last task in the graph that failed. For more information, check TASK_AUTO_RETRY_ATTEMPTS docs.
	// Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically retry the task graphs from the last task in the graph that failed. For more information, check [TASK_AUTO_RETRY_ATTEMPTS docs](https://docs.snowflake.com/en/sql-reference/parameters#task-auto-retry-attempts).
	TaskAutoRetryAttempts *float64 `json:"taskAutoRetryAttempts,omitempty" tf:"task_auto_retry_attempts,omitempty"`

	// (String) Specifies the input format for the TIME data type. For more information, see Date and time input and output formats. Any valid, supported time format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session). For more information, check TIME_INPUT_FORMAT docs.
	// Specifies the input format for the TIME data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). Any valid, supported time format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session). For more information, check [TIME_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#time-input-format).
	TimeInputFormat *string `json:"timeInputFormat,omitempty" tf:"time_input_format,omitempty"`

	// (String) Specifies the display format for the TIME data type. For more information, see Date and time input and output formats. For more information, check TIME_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIME data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIME_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#time-output-format).
	TimeOutputFormat *string `json:"timeOutputFormat,omitempty" tf:"time_output_format,omitempty"`

	// (Boolean) Specifies whether the DATEADD function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days. For more information, check TIMESTAMP_DAY_IS_ALWAYS_24H docs.
	// Specifies whether the [DATEADD](https://docs.snowflake.com/en/sql-reference/functions/dateadd) function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days. For more information, check [TIMESTAMP_DAY_IS_ALWAYS_24H docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-day-is-always-24h).
	TimestampDayIsAlways24H *bool `json:"timestampDayIsAlways24H,omitempty" tf:"timestamp_day_is_always_24h,omitempty"`

	// (String) Specifies the input format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. Any valid, supported timestamp format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session). For more information, check TIMESTAMP_INPUT_FORMAT docs.
	// Specifies the input format for the TIMESTAMP data type alias. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). Any valid, supported timestamp format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session). For more information, check [TIMESTAMP_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-input-format).
	TimestampInputFormat *string `json:"timestampInputFormat,omitempty" tf:"timestamp_input_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_LTZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_LTZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_LTZ data type. If no format is specified, defaults to [TIMESTAMP_OUTPUT_FORMAT](https://docs.snowflake.com/en/sql-reference/parameters#label-timestamp-output-format). For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_LTZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-ltz-output-format).
	TimestampLtzOutputFormat *string `json:"timestampLtzOutputFormat,omitempty" tf:"timestamp_ltz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_NTZ data type. For more information, check TIMESTAMP_NTZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_NTZ data type. For more information, check [TIMESTAMP_NTZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-ntz-output-format).
	TimestampNtzOutputFormat *string `json:"timestampNtzOutputFormat,omitempty" tf:"timestamp_ntz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP data type alias. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-output-format).
	TimestampOutputFormat *string `json:"timestampOutputFormat,omitempty" tf:"timestamp_output_format,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to. For more information, check TIMESTAMP_TYPE_MAPPING docs.
	// Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to. For more information, check [TIMESTAMP_TYPE_MAPPING docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-type-mapping).
	TimestampTypeMapping *string `json:"timestampTypeMapping,omitempty" tf:"timestamp_type_mapping,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_TZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_TZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_TZ data type. If no format is specified, defaults to [TIMESTAMP_OUTPUT_FORMAT](https://docs.snowflake.com/en/sql-reference/parameters#label-timestamp-output-format). For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_TZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-tz-output-format).
	TimestampTzOutputFormat *string `json:"timestampTzOutputFormat,omitempty" tf:"timestamp_tz_output_format,omitempty"`

	// (String) Specifies the time zone for the session. You can specify a time zone name or a link name from release 2021a of the IANA Time Zone Database (e.g. America/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.). For more information, check TIMEZONE docs.
	// Specifies the time zone for the session. You can specify a [time zone name](https://data.iana.org/time-zones/tzdb-2021a/zone1970.tab) or a [link name](https://data.iana.org/time-zones/tzdb-2021a/backward) from release 2021a of the [IANA Time Zone Database](https://www.iana.org/time-zones) (e.g. America/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.). For more information, check [TIMEZONE docs](https://docs.snowflake.com/en/sql-reference/parameters#timezone).
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (String) Controls how trace events are ingested into the event table. For more information about trace levels, see Setting trace level. For more information, check TRACE_LEVEL docs.
	// Controls how trace events are ingested into the event table. For more information about trace levels, see [Setting trace level](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing-trace-level). For more information, check [TRACE_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#trace-level).
	TraceLevel *string `json:"traceLevel,omitempty" tf:"trace_level,omitempty"`

	// autocommit transaction returns with an error. For more information, check TRANSACTION_ABORT_ON_ERROR docs.
	// Specifies the action to perform when a statement issued within a non-autocommit transaction returns with an error. For more information, check [TRANSACTION_ABORT_ON_ERROR docs](https://docs.snowflake.com/en/sql-reference/parameters#transaction-abort-on-error).
	TransactionAbortOnError *bool `json:"transactionAbortOnError,omitempty" tf:"transaction_abort_on_error,omitempty"`

	// (String) Specifies the isolation level for transactions in the user session. For more information, check TRANSACTION_DEFAULT_ISOLATION_LEVEL docs.
	// Specifies the isolation level for transactions in the user session. For more information, check [TRANSACTION_DEFAULT_ISOLATION_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#transaction-default-isolation-level).
	TransactionDefaultIsolationLevel *string `json:"transactionDefaultIsolationLevel,omitempty" tf:"transaction_default_isolation_level,omitempty"`

	// digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with the YY date format component (i.e. years represented as 2 digits). For more information, check TWO_DIGIT_CENTURY_START docs.
	// Specifies the “century start” year for 2-digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with the `YY` date format component (i.e. years represented as 2 digits). For more information, check [TWO_DIGIT_CENTURY_START docs](https://docs.snowflake.com/en/sql-reference/parameters#two-digit-century-start).
	TwoDigitCenturyStart *float64 `json:"twoDigitCenturyStart,omitempty" tf:"two_digit_century_start,omitempty"`

	// default) value specified for a constraint property returns an error. For more information, check UNSUPPORTED_DDL_ACTION docs.
	// Determines if an unsupported (i.e. non-default) value specified for a constraint property returns an error. For more information, check [UNSUPPORTED_DDL_ACTION docs](https://docs.snowflake.com/en/sql-reference/parameters#unsupported-ddl-action).
	UnsupportedDdlAction *string `json:"unsupportedDdlAction,omitempty" tf:"unsupported_ddl_action,omitempty"`

	// (Boolean) Specifies whether to reuse persisted query results, if available, when a matching query is submitted. For more information, check USE_CACHED_RESULT docs.
	// Specifies whether to reuse persisted query results, if available, when a matching query is submitted. For more information, check [USE_CACHED_RESULT docs](https://docs.snowflake.com/en/sql-reference/parameters#use-cached-result).
	UseCachedResult *bool `json:"useCachedResult,omitempty" tf:"use_cached_result,omitempty"`

	// insensitive): %s. (Conflicts with warehouse). For more information about warehouses, see docs. For more information, check USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE docs.
	// Specifies the size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size. Once a task has successfully completed a few runs, Snowflake ignores this parameter setting. Valid values are (case-insensitive): %s. (Conflicts with warehouse). For more information about warehouses, see [docs](./warehouse). For more information, check [USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-managed-initial-warehouse-size).
	UserTaskManagedInitialWarehouseSize *string `json:"userTaskManagedInitialWarehouseSize,omitempty" tf:"user_task_managed_initial_warehouse_size,omitempty"`

	// (Number) Minimum amount of time between Triggered Task executions in seconds For more information, check USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS docs.
	// Minimum amount of time between Triggered Task executions in seconds For more information, check [USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-minimum-trigger-interval-in-seconds).
	UserTaskMinimumTriggerIntervalInSeconds *float64 `json:"userTaskMinimumTriggerIntervalInSeconds,omitempty" tf:"user_task_minimum_trigger_interval_in_seconds,omitempty"`

	// (Number) Specifies the time limit on a single run of the task before it times out (in milliseconds). For more information, check USER_TASK_TIMEOUT_MS docs.
	// Specifies the time limit on a single run of the task before it times out (in milliseconds). For more information, check [USER_TASK_TIMEOUT_MS docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-timeout-ms).
	UserTaskTimeoutMs *float64 `json:"userTaskTimeoutMs,omitempty" tf:"user_task_timeout_ms,omitempty"`

	// managed compute resources for runs of this task. Due to Snowflake limitations warehouse identifier can consist of only upper-cased letters. (Conflicts with user_task_managed_initial_warehouse_size) For more information about this resource, see docs.
	// The warehouse the task will use. Omit this parameter to use Snowflake-managed compute resources for runs of this task. Due to Snowflake limitations warehouse identifier can consist of only upper-cased letters. (Conflicts with user_task_managed_initial_warehouse_size) For more information about this resource, see [docs](./warehouse).
	Warehouse *string `json:"warehouse,omitempty" tf:"warehouse,omitempty"`

	// (Number) Specifies how the weeks in a given year are computed. 0: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year. 1: January 1 is included in the first week of the year and December 31 is included in the last week of the year. For more information, check WEEK_OF_YEAR_POLICY docs.
	// Specifies how the weeks in a given year are computed. `0`: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year. `1`: January 1 is included in the first week of the year and December 31 is included in the last week of the year. For more information, check [WEEK_OF_YEAR_POLICY docs](https://docs.snowflake.com/en/sql-reference/parameters#week-of-year-policy).
	WeekOfYearPolicy *float64 `json:"weekOfYearPolicy,omitempty" tf:"week_of_year_policy,omitempty"`

	// related date functions). 0: Legacy Snowflake behavior is used (i.e. ISO-like semantics). 1 (Monday) to 7 (Sunday): All the week-related functions use weeks that start on the specified day of the week. For more information, check WEEK_START docs.
	// Specifies the first day of the week (used by week-related date functions). `0`: Legacy Snowflake behavior is used (i.e. ISO-like semantics). `1` (Monday) to `7` (Sunday): All the week-related functions use weeks that start on the specified day of the week. For more information, check [WEEK_START docs](https://docs.snowflake.com/en/sql-reference/parameters#week-start).
	WeekStart *float64 `json:"weekStart,omitempty" tf:"week_start,omitempty"`

	// (String) Specifies a Boolean SQL expression; multiple conditions joined with AND/OR are supported. When a task is triggered (based on its SCHEDULE or AFTER setting), it validates the conditions of the expression to determine whether to execute. If the conditions of the expression are not met, then the task skips the current run. Any tasks that identify this task as a predecessor also don’t run.
	// Specifies a Boolean SQL expression; multiple conditions joined with AND/OR are supported. When a task is triggered (based on its SCHEDULE or AFTER setting), it validates the conditions of the expression to determine whether to execute. If the conditions of the expression are not met, then the task skips the current run. Any tasks that identify this task as a predecessor also don’t run.
	When *string `json:"when,omitempty" tf:"when,omitempty"`
}

type TaskParameters struct {

	// progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption). For more information, check ABORT_DETACHED_QUERY docs.
	// Specifies the action that Snowflake performs for in-progress queries if connectivity is lost due to abrupt termination of a session (e.g. network outage, browser termination, service interruption). For more information, check [ABORT_DETACHED_QUERY docs](https://docs.snowflake.com/en/sql-reference/parameters#abort-detached-query).
	// +kubebuilder:validation:Optional
	AbortDetachedQuery *bool `json:"abortDetachedQuery,omitempty" tf:"abort_detached_query,omitempty"`

	// (Set of String) Specifies one or more predecessor tasks for the current task. Use this option to create a DAG of tasks or add this task to an existing DAG. A DAG is a series of tasks that starts with a scheduled root task and is linked together by dependencies. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies one or more predecessor tasks for the current task. Use this option to [create a DAG](https://docs.snowflake.com/en/user-guide/tasks-graphs.html#label-task-dag) of tasks or add this task to an existing DAG. A DAG is a series of tasks that starts with a scheduled root task and is linked together by dependencies. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	// +kubebuilder:validation:Optional
	// +listType=set
	After []*string `json:"after,omitempty" tf:"after,omitempty"`

	// uses special value that cannot be set in the configuration manually (default)) By default, Snowflake ensures that only one instance of a particular DAG is allowed to run at a time, setting the parameter value to TRUE permits DAG runs to overlap. Available options are: "true" or "false". When the value is not set in the configuration the provider will put "default" there which means to use the Snowflake default for this value.
	// (Default: fallback to Snowflake default - uses special value that cannot be set in the configuration manually (`default`)) By default, Snowflake ensures that only one instance of a particular DAG is allowed to run at a time, setting the parameter value to TRUE permits DAG runs to overlap. Available options are: "true" or "false". When the value is not set in the configuration the provider will put "default" there which means to use the Snowflake default for this value.
	// +kubebuilder:validation:Optional
	AllowOverlappingExecution *string `json:"allowOverlappingExecution,omitempty" tf:"allow_overlapping_execution,omitempty"`

	// (Boolean) Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the statement successfully completes. For more information, see Transactions. For more information, check AUTOCOMMIT docs.
	// Specifies whether autocommit is enabled for the session. Autocommit determines whether a DML statement, when executed without an active transaction, is automatically committed after the statement successfully completes. For more information, see [Transactions](https://docs.snowflake.com/en/sql-reference/transactions). For more information, check [AUTOCOMMIT docs](https://docs.snowflake.com/en/sql-reference/parameters#autocommit).
	// +kubebuilder:validation:Optional
	Autocommit *bool `json:"autocommit,omitempty" tf:"autocommit,omitempty"`

	// to-BINARY conversion functions. For more information, see Binary input and output. For more information, check BINARY_INPUT_FORMAT docs.
	// The format of VARCHAR values passed as input to VARCHAR-to-BINARY conversion functions. For more information, see [Binary input and output](https://docs.snowflake.com/en/sql-reference/binary-input-output). For more information, check [BINARY_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#binary-input-format).
	// +kubebuilder:validation:Optional
	BinaryInputFormat *string `json:"binaryInputFormat,omitempty" tf:"binary_input_format,omitempty"`

	// to-VARCHAR conversion functions. For more information, see Binary input and output. For more information, check BINARY_OUTPUT_FORMAT docs.
	// The format for VARCHAR values returned as output by BINARY-to-VARCHAR conversion functions. For more information, see [Binary input and output](https://docs.snowflake.com/en/sql-reference/binary-input-output). For more information, check [BINARY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#binary-output-format).
	// +kubebuilder:validation:Optional
	BinaryOutputFormat *string `json:"binaryOutputFormat,omitempty" tf:"binary_output_format,omitempty"`

	// (Number) Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB). For more information, check CLIENT_MEMORY_LIMIT docs.
	// Parameter that specifies the maximum amount of memory the JDBC driver or ODBC driver should use for the result set from queries (in MB). For more information, check [CLIENT_MEMORY_LIMIT docs](https://docs.snowflake.com/en/sql-reference/parameters#client-memory-limit).
	// +kubebuilder:validation:Optional
	ClientMemoryLimit *float64 `json:"clientMemoryLimit,omitempty" tf:"client_memory_limit,omitempty"`

	// (Boolean) For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all databases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes more quickly. For more information, check CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX docs.
	// For specific ODBC functions and JDBC methods, this parameter can change the default search scope from all databases/schemas to the current database/schema. The narrower search typically returns fewer rows and executes more quickly. For more information, check [CLIENT_METADATA_REQUEST_USE_CONNECTION_CTX docs](https://docs.snowflake.com/en/sql-reference/parameters#client-metadata-request-use-connection-ctx).
	// +kubebuilder:validation:Optional
	ClientMetadataRequestUseConnectionCtx *bool `json:"clientMetadataRequestUseConnectionCtx,omitempty" tf:"client_metadata_request_use_connection_ctx,omitempty"`

	// fetch large result sets. The driver will attempt to honor the parameter value, but defines the minimum and maximum values (depending on your system’s resources) to improve performance. For more information, check CLIENT_PREFETCH_THREADS docs.
	// Parameter that specifies the number of threads used by the client to pre-fetch large result sets. The driver will attempt to honor the parameter value, but defines the minimum and maximum values (depending on your system’s resources) to improve performance. For more information, check [CLIENT_PREFETCH_THREADS docs](https://docs.snowflake.com/en/sql-reference/parameters#client-prefetch-threads).
	// +kubebuilder:validation:Optional
	ClientPrefetchThreads *float64 `json:"clientPrefetchThreads,omitempty" tf:"client_prefetch_threads,omitempty"`

	// (Number) Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks. For more information, check CLIENT_RESULT_CHUNK_SIZE docs.
	// Parameter that specifies the maximum size of each set (or chunk) of query results to download (in MB). The JDBC driver downloads query results in chunks. For more information, check [CLIENT_RESULT_CHUNK_SIZE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-result-chunk-size).
	// +kubebuilder:validation:Optional
	ClientResultChunkSize *float64 `json:"clientResultChunkSize,omitempty" tf:"client_result_chunk_size,omitempty"`

	// insensitively in ResultSet.get* methods in JDBC. For more information, check CLIENT_RESULT_COLUMN_CASE_INSENSITIVE docs.
	// Parameter that indicates whether to match column name case-insensitively in ResultSet.get* methods in JDBC. For more information, check [CLIENT_RESULT_COLUMN_CASE_INSENSITIVE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-result-column-case-insensitive).
	// +kubebuilder:validation:Optional
	ClientResultColumnCaseInsensitive *bool `json:"clientResultColumnCaseInsensitive,omitempty" tf:"client_result_column_case_insensitive,omitempty"`

	// (Boolean) Parameter that indicates whether to force a user to log in again after a period of inactivity in the session. For more information, check CLIENT_SESSION_KEEP_ALIVE docs.
	// Parameter that indicates whether to force a user to log in again after a period of inactivity in the session. For more information, check [CLIENT_SESSION_KEEP_ALIVE docs](https://docs.snowflake.com/en/sql-reference/parameters#client-session-keep-alive).
	// +kubebuilder:validation:Optional
	ClientSessionKeepAlive *bool `json:"clientSessionKeepAlive,omitempty" tf:"client_session_keep_alive,omitempty"`

	// between client attempts to update the token for the session. For more information, check CLIENT_SESSION_KEEP_ALIVE_HEARTBEAT_FREQUENCY docs.
	// Number of seconds in-between client attempts to update the token for the session. For more information, check [CLIENT_SESSION_KEEP_ALIVE_HEARTBEAT_FREQUENCY docs](https://docs.snowflake.com/en/sql-reference/parameters#client-session-keep-alive-heartbeat-frequency).
	// +kubebuilder:validation:Optional
	ClientSessionKeepAliveHeartbeatFrequency *float64 `json:"clientSessionKeepAliveHeartbeatFrequency,omitempty" tf:"client_session_keep_alive_heartbeat_frequency,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data. For more information, check CLIENT_TIMESTAMP_TYPE_MAPPING docs.
	// Specifies the [TIMESTAMP_* variation](https://docs.snowflake.com/en/sql-reference/data-types-datetime.html#label-datatypes-timestamp-variations) to use when binding timestamp variables for JDBC or ODBC applications that use the bind API to load data. For more information, check [CLIENT_TIMESTAMP_TYPE_MAPPING docs](https://docs.snowflake.com/en/sql-reference/parameters#client-timestamp-type-mapping).
	// +kubebuilder:validation:Optional
	ClientTimestampTypeMapping *string `json:"clientTimestampTypeMapping,omitempty" tf:"client_timestamp_type_mapping,omitempty"`

	// (String) Specifies a comment for the task.
	// Specifies a comment for the task.
	// +kubebuilder:validation:Optional
	Comment *string `json:"comment,omitempty" tf:"comment,omitempty"`

	// (String) Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format.
	// Specifies a string representation of key value pairs that can be accessed by all tasks in the task graph. Must be in JSON format.
	// +kubebuilder:validation:Optional
	Config *string `json:"config,omitempty" tf:"config,omitempty"`

	// (String) The database in which to create the task. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// The database in which to create the task. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	// +kubebuilder:validation:Optional
	Database *string `json:"database,omitempty" tf:"database,omitempty"`

	// (String) Specifies the input format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_INPUT_FORMAT docs.
	// Specifies the input format for the DATE data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [DATE_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#date-input-format).
	// +kubebuilder:validation:Optional
	DateInputFormat *string `json:"dateInputFormat,omitempty" tf:"date_input_format,omitempty"`

	// (String) Specifies the display format for the DATE data type. For more information, see Date and time input and output formats. For more information, check DATE_OUTPUT_FORMAT docs.
	// Specifies the display format for the DATE data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [DATE_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#date-output-format).
	// +kubebuilder:validation:Optional
	DateOutputFormat *string `json:"dateOutputFormat,omitempty" tf:"date_output_format,omitempty"`

	// (Boolean) Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the unloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table). For more information, check ENABLE_UNLOAD_PHYSICAL_TYPE_OPTIMIZATION docs.
	// Specifies whether to set the schema for unloaded Parquet files based on the logical column data types (i.e. the types in the unload SQL query or source table) or on the unloaded column values (i.e. the smallest data types and precision that support the values in the output columns of the unload SQL statement or source table). For more information, check [ENABLE_UNLOAD_PHYSICAL_TYPE_OPTIMIZATION docs](https://docs.snowflake.com/en/sql-reference/parameters#enable-unload-physical-type-optimization).
	// +kubebuilder:validation:Optional
	EnableUnloadPhysicalTypeOptimization *bool `json:"enableUnloadPhysicalTypeOptimization,omitempty" tf:"enable_unload_physical_type_optimization,omitempty"`

	// (String) Specifies the name of the notification integration used for error notifications. Due to technical limitations (read more here), avoid using the following characters: |, ., ". For more information about this resource, see docs.
	// Specifies the name of the notification integration used for error notifications. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`. For more information about this resource, see [docs](./notification_integration).
	// +kubebuilder:validation:Optional
	ErrorIntegration *string `json:"errorIntegration,omitempty" tf:"error_integration,omitempty"`

	// (Boolean) Specifies whether to return an error when the MERGE command is used to update or delete a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_MERGE docs.
	// Specifies whether to return an error when the [MERGE](https://docs.snowflake.com/en/sql-reference/sql/merge) command is used to update or delete a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check [ERROR_ON_NONDETERMINISTIC_MERGE docs](https://docs.snowflake.com/en/sql-reference/parameters#error-on-nondeterministic-merge).
	// +kubebuilder:validation:Optional
	ErrorOnNondeterministicMerge *bool `json:"errorOnNondeterministicMerge,omitempty" tf:"error_on_nondeterministic_merge,omitempty"`

	// (Boolean) Specifies whether to return an error when the UPDATE command is used to update a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check ERROR_ON_NONDETERMINISTIC_UPDATE docs.
	// Specifies whether to return an error when the [UPDATE](https://docs.snowflake.com/en/sql-reference/sql/update) command is used to update a target row that joins multiple source rows and the system cannot determine the action to perform on the target row. For more information, check [ERROR_ON_NONDETERMINISTIC_UPDATE docs](https://docs.snowflake.com/en/sql-reference/parameters#error-on-nondeterministic-update).
	// +kubebuilder:validation:Optional
	ErrorOnNondeterministicUpdate *bool `json:"errorOnNondeterministicUpdate,omitempty" tf:"error_on_nondeterministic_update,omitempty"`

	// (String) Specifies the name of a root task that the finalizer task is associated with. Finalizer tasks run after all other tasks in the task graph run to completion. You can define the SQL of a finalizer task to handle notifications and the release and cleanup of resources that a task graph uses. For more information, see Release and cleanup of task graphs. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies the name of a root task that the finalizer task is associated with. Finalizer tasks run after all other tasks in the task graph run to completion. You can define the SQL of a finalizer task to handle notifications and the release and cleanup of resources that a task graph uses. For more information, see [Release and cleanup of task graphs](https://docs.snowflake.com/en/user-guide/tasks-graphs.html#label-finalizer-task). Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	// +kubebuilder:validation:Optional
	Finalize *string `json:"finalize,omitempty" tf:"finalize,omitempty"`

	// (String) Display format for GEOGRAPHY values. For more information, check GEOGRAPHY_OUTPUT_FORMAT docs.
	// Display format for [GEOGRAPHY values](https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html#label-data-types-geography). For more information, check [GEOGRAPHY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#geography-output-format).
	// +kubebuilder:validation:Optional
	GeographyOutputFormat *string `json:"geographyOutputFormat,omitempty" tf:"geography_output_format,omitempty"`

	// (String) Display format for GEOMETRY values. For more information, check GEOMETRY_OUTPUT_FORMAT docs.
	// Display format for [GEOMETRY values](https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html#label-data-types-geometry). For more information, check [GEOMETRY_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#geometry-output-format).
	// +kubebuilder:validation:Optional
	GeometryOutputFormat *string `json:"geometryOutputFormat,omitempty" tf:"geometry_output_format,omitempty"`

	// (Number) Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element. For more information, check JSON_INDENT docs.
	// Specifies the number of blank spaces to indent each new element in JSON output in the session. Also specifies whether to insert newline characters after each element. For more information, check [JSON_INDENT docs](https://docs.snowflake.com/en/sql-reference/parameters#json-indent).
	// +kubebuilder:validation:Optional
	JSONIndent *float64 `json:"jsonIndent,omitempty" tf:"json_indent,omitempty"`

	// (Boolean) Specifies how JDBC processes TIMESTAMP_NTZ values. For more information, check JDBC_TREAT_TIMESTAMP_NTZ_AS_UTC docs.
	// Specifies how JDBC processes TIMESTAMP_NTZ values. For more information, check [JDBC_TREAT_TIMESTAMP_NTZ_AS_UTC docs](https://docs.snowflake.com/en/sql-reference/parameters#jdbc-treat-timestamp-ntz-as-utc).
	// +kubebuilder:validation:Optional
	JdbcTreatTimestampNtzAsUtc *bool `json:"jdbcTreatTimestampNtzAsUtc,omitempty" tf:"jdbc_treat_timestamp_ntz_as_utc,omitempty"`

	// (Boolean) Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the TIMEZONE parameter) for the getDate(), getTime(), and getTimestamp() methods of the ResultSet class. For more information, check JDBC_USE_SESSION_TIMEZONE docs.
	// Specifies whether the JDBC Driver uses the time zone of the JVM or the time zone of the session (specified by the [TIMEZONE](https://docs.snowflake.com/en/sql-reference/parameters#label-timezone) parameter) for the getDate(), getTime(), and getTimestamp() methods of the ResultSet class. For more information, check [JDBC_USE_SESSION_TIMEZONE docs](https://docs.snowflake.com/en/sql-reference/parameters#jdbc-use-session-timezone).
	// +kubebuilder:validation:Optional
	JdbcUseSessionTimezone *bool `json:"jdbcUseSessionTimezone,omitempty" tf:"jdbc_use_session_timezone,omitempty"`

	// (Number) Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement. For more information, check LOCK_TIMEOUT docs.
	// Number of seconds to wait while trying to lock a resource, before timing out and aborting the statement. For more information, check [LOCK_TIMEOUT docs](https://docs.snowflake.com/en/sql-reference/parameters#lock-timeout).
	// +kubebuilder:validation:Optional
	LockTimeout *float64 `json:"lockTimeout,omitempty" tf:"lock_timeout,omitempty"`

	// (String) Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at the specified level (and at more severe levels) are ingested. For more information about log levels, see Setting log level. For more information, check LOG_LEVEL docs.
	// Specifies the severity level of messages that should be ingested and made available in the active event table. Messages at the specified level (and at more severe levels) are ingested. For more information about log levels, see [Setting log level](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-log-level). For more information, check [LOG_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#log-level).
	// +kubebuilder:validation:Optional
	LogLevel *string `json:"logLevel,omitempty" tf:"log_level,omitempty"`

	// statement capability. For more information, check MULTI_STATEMENT_COUNT docs.
	// Number of statements to execute when using the multi-statement capability. For more information, check [MULTI_STATEMENT_COUNT docs](https://docs.snowflake.com/en/sql-reference/parameters#multi-statement-count).
	// +kubebuilder:validation:Optional
	MultiStatementCount *float64 `json:"multiStatementCount,omitempty" tf:"multi_statement_count,omitempty"`

	// (String) Specifies the identifier for the task; must be unique for the database and schema in which the task is created. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// Specifies the identifier for the task; must be unique for the database and schema in which the task is created. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// incremented column in increasing or decreasing order. For more information, check NOORDER_SEQUENCE_AS_DEFAULT docs.
	// Specifies whether the ORDER or NOORDER property is set by default when you create a new sequence or add a new table column. The ORDER and NOORDER properties determine whether or not the values are generated for the sequence or auto-incremented column in [increasing or decreasing order](https://docs.snowflake.com/en/user-guide/querying-sequences.html#label-querying-sequences-increasing-values). For more information, check [NOORDER_SEQUENCE_AS_DEFAULT docs](https://docs.snowflake.com/en/sql-reference/parameters#noorder-sequence-as-default).
	// +kubebuilder:validation:Optional
	NoorderSequenceAsDefault *bool `json:"noorderSequenceAsDefault,omitempty" tf:"noorder_sequence_as_default,omitempty"`

	// (Boolean) Specifies how ODBC processes columns that have a scale of zero (0). For more information, check ODBC_TREAT_DECIMAL_AS_INT docs.
	// Specifies how ODBC processes columns that have a scale of zero (0). For more information, check [ODBC_TREAT_DECIMAL_AS_INT docs](https://docs.snowflake.com/en/sql-reference/parameters#odbc-treat-decimal-as-int).
	// +kubebuilder:validation:Optional
	OdbcTreatDecimalAsInt *bool `json:"odbcTreatDecimalAsInt,omitempty" tf:"odbc_treat_decimal_as_int,omitempty"`

	// (String) Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the QUERY_HISTORY, QUERY_HISTORY_BY_* functions. For more information, check QUERY_TAG docs.
	// Optional string that can be used to tag queries and other SQL statements executed within a session. The tags are displayed in the output of the [QUERY_HISTORY, QUERY_HISTORY_BY_*](https://docs.snowflake.com/en/sql-reference/functions/query_history) functions. For more information, check [QUERY_TAG docs](https://docs.snowflake.com/en/sql-reference/parameters#query-tag).
	// +kubebuilder:validation:Optional
	QueryTag *string `json:"queryTag,omitempty" tf:"query_tag,omitempty"`

	// quoted object identifiers are stored and resolved as uppercase letters. By default, Snowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers (see Identifier resolution). You can use this parameter in situations in which third-party applications always use double quotes around identifiers. For more information, check QUOTED_IDENTIFIERS_IGNORE_CASE docs.
	// Specifies whether letters in double-quoted object identifiers are stored and resolved as uppercase letters. By default, Snowflake preserves the case of alphabetic characters when storing and resolving double-quoted identifiers (see [Identifier resolution](https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html#label-identifier-casing)). You can use this parameter in situations in which [third-party applications always use double quotes around identifiers](https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html#label-identifier-casing-parameter). For more information, check [QUOTED_IDENTIFIERS_IGNORE_CASE docs](https://docs.snowflake.com/en/sql-reference/parameters#quoted-identifiers-ignore-case).
	// +kubebuilder:validation:Optional
	QuotedIdentifiersIgnoreCase *bool `json:"quotedIdentifiersIgnoreCase,omitempty" tf:"quoted_identifiers_ignore_case,omitempty"`

	// (Number) Specifies the maximum number of rows returned in a result set. A value of 0 specifies no maximum. For more information, check ROWS_PER_RESULTSET docs.
	// Specifies the maximum number of rows returned in a result set. A value of 0 specifies no maximum. For more information, check [ROWS_PER_RESULTSET docs](https://docs.snowflake.com/en/sql-reference/parameters#rows-per-resultset).
	// +kubebuilder:validation:Optional
	RowsPerResultset *float64 `json:"rowsPerResultset,omitempty" tf:"rows_per_resultset,omitempty"`

	// (String) Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via AWS PrivateLink for Amazon S3 use this endpoint to connect. For more information, see Accessing Internal stages with dedicated interface endpoints. For more information, check S3_STAGE_VPCE_DNS_NAME docs.
	// Specifies the DNS name of an Amazon S3 interface endpoint. Requests sent to the internal stage of an account via [AWS PrivateLink for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html) use this endpoint to connect. For more information, see [Accessing Internal stages with dedicated interface endpoints](https://docs.snowflake.com/en/user-guide/private-internal-stages-aws.html#label-aws-privatelink-internal-stage-network-isolation). For more information, check [S3_STAGE_VPCE_DNS_NAME docs](https://docs.snowflake.com/en/sql-reference/parameters#s3-stage-vpce-dns-name).
	// +kubebuilder:validation:Optional
	S3StageVpceDNSName *string `json:"s3StageVpceDnsName,omitempty" tf:"s3_stage_vpce_dns_name,omitempty"`

	// (String) Any single SQL statement, or a call to a stored procedure, executed when the task runs.
	// Any single SQL statement, or a call to a stored procedure, executed when the task runs.
	// +kubebuilder:validation:Optional
	SQLStatement *string `json:"sqlStatement,omitempty" tf:"sql_statement,omitempty"`

	// fields minutes or using_cron should be set) (see below for nested schema)
	// The schedule for periodically running the task. This can be a cron or interval in minutes. (Conflicts with finalize and after; when set, one of the sub-fields `minutes` or `using_cron` should be set)
	// +kubebuilder:validation:Optional
	Schedule []ScheduleParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// (String) The schema in which to create the task. Due to technical limitations (read more here), avoid using the following characters: |, ., ".
	// The schema in which to create the task. Due to technical limitations (read more [here](../guides/identifiers_rework_design_decisions#known-limitations-and-identifier-recommendations)), avoid using the following characters: `|`, `.`, `"`.
	// +kubebuilder:validation:Optional
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// separated list of identifiers. An identifier can be a fully or partially qualified schema name. For more information, check SEARCH_PATH docs.
	// Specifies the path to search to resolve unqualified object names in queries. For more information, see [Name resolution in queries](https://docs.snowflake.com/en/sql-reference/name-resolution.html#label-object-name-resolution-search-path). Comma-separated list of identifiers. An identifier can be a fully or partially qualified schema name. For more information, check [SEARCH_PATH docs](https://docs.snowflake.com/en/sql-reference/parameters#search-path).
	// +kubebuilder:validation:Optional
	SearchPath *string `json:"searchPath,omitempty" tf:"search_path,omitempty"`

	// (Boolean) Specifies if the task should be started or suspended.
	// Specifies if the task should be started or suspended.
	// +kubebuilder:validation:Optional
	Started *bool `json:"started,omitempty" tf:"started,omitempty"`

	// (Number) Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the MAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged. For more information, check STATEMENT_QUEUED_TIMEOUT_IN_SECONDS docs.
	// Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the [MAX_CONCURRENCY_LEVEL](https://docs.snowflake.com/en/sql-reference/parameters#label-max-concurrency-level) parameter to ensure a warehouse is never backlogged. For more information, check [STATEMENT_QUEUED_TIMEOUT_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#statement-queued-timeout-in-seconds).
	// +kubebuilder:validation:Optional
	StatementQueuedTimeoutInSeconds *float64 `json:"statementQueuedTimeoutInSeconds,omitempty" tf:"statement_queued_timeout_in_seconds,omitempty"`

	// (Number) Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system. For more information, check STATEMENT_TIMEOUT_IN_SECONDS docs.
	// Amount of time, in seconds, after which a running SQL statement (query, DDL, DML, etc.) is canceled by the system. For more information, check [STATEMENT_TIMEOUT_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#statement-timeout-in-seconds).
	// +kubebuilder:validation:Optional
	StatementTimeoutInSeconds *float64 `json:"statementTimeoutInSeconds,omitempty" tf:"statement_timeout_in_seconds,omitempty"`

	// standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and languages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON. For more information, check STRICT_JSON_OUTPUT docs.
	// This parameter specifies whether JSON output in a session is compatible with the general standard (as described by [http://json.org](http://json.org)). By design, Snowflake allows JSON input that contains non-standard values; however, these non-standard values might result in Snowflake outputting JSON that is incompatible with other platforms and languages. This parameter, when enabled, ensures that Snowflake outputs valid/compatible JSON. For more information, check [STRICT_JSON_OUTPUT docs](https://docs.snowflake.com/en/sql-reference/parameters#strict-json-output).
	// +kubebuilder:validation:Optional
	StrictJSONOutput *bool `json:"strictJsonOutput,omitempty" tf:"strict_json_output,omitempty"`

	// (Number) Specifies the number of consecutive failed task runs after which the current task is suspended automatically. The default is 0 (no automatic suspension). For more information, check SUSPEND_TASK_AFTER_NUM_FAILURES docs.
	// Specifies the number of consecutive failed task runs after which the current task is suspended automatically. The default is 0 (no automatic suspension). For more information, check [SUSPEND_TASK_AFTER_NUM_FAILURES docs](https://docs.snowflake.com/en/sql-reference/parameters#suspend-task-after-num-failures).
	// +kubebuilder:validation:Optional
	SuspendTaskAfterNumFailures *float64 `json:"suspendTaskAfterNumFailures,omitempty" tf:"suspend_task_after_num_failures,omitempty"`

	// (Number) Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically retry the task graphs from the last task in the graph that failed. For more information, check TASK_AUTO_RETRY_ATTEMPTS docs.
	// Specifies the number of automatic task graph retry attempts. If any task graphs complete in a FAILED state, Snowflake can automatically retry the task graphs from the last task in the graph that failed. For more information, check [TASK_AUTO_RETRY_ATTEMPTS docs](https://docs.snowflake.com/en/sql-reference/parameters#task-auto-retry-attempts).
	// +kubebuilder:validation:Optional
	TaskAutoRetryAttempts *float64 `json:"taskAutoRetryAttempts,omitempty" tf:"task_auto_retry_attempts,omitempty"`

	// (String) Specifies the input format for the TIME data type. For more information, see Date and time input and output formats. Any valid, supported time format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session). For more information, check TIME_INPUT_FORMAT docs.
	// Specifies the input format for the TIME data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). Any valid, supported time format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of times stored in the system during the session). For more information, check [TIME_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#time-input-format).
	// +kubebuilder:validation:Optional
	TimeInputFormat *string `json:"timeInputFormat,omitempty" tf:"time_input_format,omitempty"`

	// (String) Specifies the display format for the TIME data type. For more information, see Date and time input and output formats. For more information, check TIME_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIME data type. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIME_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#time-output-format).
	// +kubebuilder:validation:Optional
	TimeOutputFormat *string `json:"timeOutputFormat,omitempty" tf:"time_output_format,omitempty"`

	// (Boolean) Specifies whether the DATEADD function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days. For more information, check TIMESTAMP_DAY_IS_ALWAYS_24H docs.
	// Specifies whether the [DATEADD](https://docs.snowflake.com/en/sql-reference/functions/dateadd) function (and its aliases) always consider a day to be exactly 24 hours for expressions that span multiple days. For more information, check [TIMESTAMP_DAY_IS_ALWAYS_24H docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-day-is-always-24h).
	// +kubebuilder:validation:Optional
	TimestampDayIsAlways24H *bool `json:"timestampDayIsAlways24H,omitempty" tf:"timestamp_day_is_always_24h,omitempty"`

	// (String) Specifies the input format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. Any valid, supported timestamp format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session). For more information, check TIMESTAMP_INPUT_FORMAT docs.
	// Specifies the input format for the TIMESTAMP data type alias. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). Any valid, supported timestamp format or AUTO (AUTO specifies that Snowflake attempts to automatically detect the format of timestamps stored in the system during the session). For more information, check [TIMESTAMP_INPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-input-format).
	// +kubebuilder:validation:Optional
	TimestampInputFormat *string `json:"timestampInputFormat,omitempty" tf:"timestamp_input_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_LTZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_LTZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_LTZ data type. If no format is specified, defaults to [TIMESTAMP_OUTPUT_FORMAT](https://docs.snowflake.com/en/sql-reference/parameters#label-timestamp-output-format). For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_LTZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-ltz-output-format).
	// +kubebuilder:validation:Optional
	TimestampLtzOutputFormat *string `json:"timestampLtzOutputFormat,omitempty" tf:"timestamp_ltz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_NTZ data type. For more information, check TIMESTAMP_NTZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_NTZ data type. For more information, check [TIMESTAMP_NTZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-ntz-output-format).
	// +kubebuilder:validation:Optional
	TimestampNtzOutputFormat *string `json:"timestampNtzOutputFormat,omitempty" tf:"timestamp_ntz_output_format,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP data type alias. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP data type alias. For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-output-format).
	// +kubebuilder:validation:Optional
	TimestampOutputFormat *string `json:"timestampOutputFormat,omitempty" tf:"timestamp_output_format,omitempty"`

	// (String) Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to. For more information, check TIMESTAMP_TYPE_MAPPING docs.
	// Specifies the TIMESTAMP_* variation that the TIMESTAMP data type alias maps to. For more information, check [TIMESTAMP_TYPE_MAPPING docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-type-mapping).
	// +kubebuilder:validation:Optional
	TimestampTypeMapping *string `json:"timestampTypeMapping,omitempty" tf:"timestamp_type_mapping,omitempty"`

	// (String) Specifies the display format for the TIMESTAMP_TZ data type. If no format is specified, defaults to TIMESTAMP_OUTPUT_FORMAT. For more information, see Date and time input and output formats. For more information, check TIMESTAMP_TZ_OUTPUT_FORMAT docs.
	// Specifies the display format for the TIMESTAMP_TZ data type. If no format is specified, defaults to [TIMESTAMP_OUTPUT_FORMAT](https://docs.snowflake.com/en/sql-reference/parameters#label-timestamp-output-format). For more information, see [Date and time input and output formats](https://docs.snowflake.com/en/sql-reference/date-time-input-output). For more information, check [TIMESTAMP_TZ_OUTPUT_FORMAT docs](https://docs.snowflake.com/en/sql-reference/parameters#timestamp-tz-output-format).
	// +kubebuilder:validation:Optional
	TimestampTzOutputFormat *string `json:"timestampTzOutputFormat,omitempty" tf:"timestamp_tz_output_format,omitempty"`

	// (String) Specifies the time zone for the session. You can specify a time zone name or a link name from release 2021a of the IANA Time Zone Database (e.g. America/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.). For more information, check TIMEZONE docs.
	// Specifies the time zone for the session. You can specify a [time zone name](https://data.iana.org/time-zones/tzdb-2021a/zone1970.tab) or a [link name](https://data.iana.org/time-zones/tzdb-2021a/backward) from release 2021a of the [IANA Time Zone Database](https://www.iana.org/time-zones) (e.g. America/Los_Angeles, Europe/London, UTC, Etc/GMT, etc.). For more information, check [TIMEZONE docs](https://docs.snowflake.com/en/sql-reference/parameters#timezone).
	// +kubebuilder:validation:Optional
	Timezone *string `json:"timezone,omitempty" tf:"timezone,omitempty"`

	// (String) Controls how trace events are ingested into the event table. For more information about trace levels, see Setting trace level. For more information, check TRACE_LEVEL docs.
	// Controls how trace events are ingested into the event table. For more information about trace levels, see [Setting trace level](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing-trace-level). For more information, check [TRACE_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#trace-level).
	// +kubebuilder:validation:Optional
	TraceLevel *string `json:"traceLevel,omitempty" tf:"trace_level,omitempty"`

	// autocommit transaction returns with an error. For more information, check TRANSACTION_ABORT_ON_ERROR docs.
	// Specifies the action to perform when a statement issued within a non-autocommit transaction returns with an error. For more information, check [TRANSACTION_ABORT_ON_ERROR docs](https://docs.snowflake.com/en/sql-reference/parameters#transaction-abort-on-error).
	// +kubebuilder:validation:Optional
	TransactionAbortOnError *bool `json:"transactionAbortOnError,omitempty" tf:"transaction_abort_on_error,omitempty"`

	// (String) Specifies the isolation level for transactions in the user session. For more information, check TRANSACTION_DEFAULT_ISOLATION_LEVEL docs.
	// Specifies the isolation level for transactions in the user session. For more information, check [TRANSACTION_DEFAULT_ISOLATION_LEVEL docs](https://docs.snowflake.com/en/sql-reference/parameters#transaction-default-isolation-level).
	// +kubebuilder:validation:Optional
	TransactionDefaultIsolationLevel *string `json:"transactionDefaultIsolationLevel,omitempty" tf:"transaction_default_isolation_level,omitempty"`

	// digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with the YY date format component (i.e. years represented as 2 digits). For more information, check TWO_DIGIT_CENTURY_START docs.
	// Specifies the “century start” year for 2-digit years (i.e. the earliest year such dates can represent). This parameter prevents ambiguous dates when importing or converting data with the `YY` date format component (i.e. years represented as 2 digits). For more information, check [TWO_DIGIT_CENTURY_START docs](https://docs.snowflake.com/en/sql-reference/parameters#two-digit-century-start).
	// +kubebuilder:validation:Optional
	TwoDigitCenturyStart *float64 `json:"twoDigitCenturyStart,omitempty" tf:"two_digit_century_start,omitempty"`

	// default) value specified for a constraint property returns an error. For more information, check UNSUPPORTED_DDL_ACTION docs.
	// Determines if an unsupported (i.e. non-default) value specified for a constraint property returns an error. For more information, check [UNSUPPORTED_DDL_ACTION docs](https://docs.snowflake.com/en/sql-reference/parameters#unsupported-ddl-action).
	// +kubebuilder:validation:Optional
	UnsupportedDdlAction *string `json:"unsupportedDdlAction,omitempty" tf:"unsupported_ddl_action,omitempty"`

	// (Boolean) Specifies whether to reuse persisted query results, if available, when a matching query is submitted. For more information, check USE_CACHED_RESULT docs.
	// Specifies whether to reuse persisted query results, if available, when a matching query is submitted. For more information, check [USE_CACHED_RESULT docs](https://docs.snowflake.com/en/sql-reference/parameters#use-cached-result).
	// +kubebuilder:validation:Optional
	UseCachedResult *bool `json:"useCachedResult,omitempty" tf:"use_cached_result,omitempty"`

	// insensitive): %s. (Conflicts with warehouse). For more information about warehouses, see docs. For more information, check USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE docs.
	// Specifies the size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size. Once a task has successfully completed a few runs, Snowflake ignores this parameter setting. Valid values are (case-insensitive): %s. (Conflicts with warehouse). For more information about warehouses, see [docs](./warehouse). For more information, check [USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-managed-initial-warehouse-size).
	// +kubebuilder:validation:Optional
	UserTaskManagedInitialWarehouseSize *string `json:"userTaskManagedInitialWarehouseSize,omitempty" tf:"user_task_managed_initial_warehouse_size,omitempty"`

	// (Number) Minimum amount of time between Triggered Task executions in seconds For more information, check USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS docs.
	// Minimum amount of time between Triggered Task executions in seconds For more information, check [USER_TASK_MINIMUM_TRIGGER_INTERVAL_IN_SECONDS docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-minimum-trigger-interval-in-seconds).
	// +kubebuilder:validation:Optional
	UserTaskMinimumTriggerIntervalInSeconds *float64 `json:"userTaskMinimumTriggerIntervalInSeconds,omitempty" tf:"user_task_minimum_trigger_interval_in_seconds,omitempty"`

	// (Number) Specifies the time limit on a single run of the task before it times out (in milliseconds). For more information, check USER_TASK_TIMEOUT_MS docs.
	// Specifies the time limit on a single run of the task before it times out (in milliseconds). For more information, check [USER_TASK_TIMEOUT_MS docs](https://docs.snowflake.com/en/sql-reference/parameters#user-task-timeout-ms).
	// +kubebuilder:validation:Optional
	UserTaskTimeoutMs *float64 `json:"userTaskTimeoutMs,omitempty" tf:"user_task_timeout_ms,omitempty"`

	// managed compute resources for runs of this task. Due to Snowflake limitations warehouse identifier can consist of only upper-cased letters. (Conflicts with user_task_managed_initial_warehouse_size) For more information about this resource, see docs.
	// The warehouse the task will use. Omit this parameter to use Snowflake-managed compute resources for runs of this task. Due to Snowflake limitations warehouse identifier can consist of only upper-cased letters. (Conflicts with user_task_managed_initial_warehouse_size) For more information about this resource, see [docs](./warehouse).
	// +kubebuilder:validation:Optional
	Warehouse *string `json:"warehouse,omitempty" tf:"warehouse,omitempty"`

	// (Number) Specifies how the weeks in a given year are computed. 0: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year. 1: January 1 is included in the first week of the year and December 31 is included in the last week of the year. For more information, check WEEK_OF_YEAR_POLICY docs.
	// Specifies how the weeks in a given year are computed. `0`: The semantics used are equivalent to the ISO semantics, in which a week belongs to a given year if at least 4 days of that week are in that year. `1`: January 1 is included in the first week of the year and December 31 is included in the last week of the year. For more information, check [WEEK_OF_YEAR_POLICY docs](https://docs.snowflake.com/en/sql-reference/parameters#week-of-year-policy).
	// +kubebuilder:validation:Optional
	WeekOfYearPolicy *float64 `json:"weekOfYearPolicy,omitempty" tf:"week_of_year_policy,omitempty"`

	// related date functions). 0: Legacy Snowflake behavior is used (i.e. ISO-like semantics). 1 (Monday) to 7 (Sunday): All the week-related functions use weeks that start on the specified day of the week. For more information, check WEEK_START docs.
	// Specifies the first day of the week (used by week-related date functions). `0`: Legacy Snowflake behavior is used (i.e. ISO-like semantics). `1` (Monday) to `7` (Sunday): All the week-related functions use weeks that start on the specified day of the week. For more information, check [WEEK_START docs](https://docs.snowflake.com/en/sql-reference/parameters#week-start).
	// +kubebuilder:validation:Optional
	WeekStart *float64 `json:"weekStart,omitempty" tf:"week_start,omitempty"`

	// (String) Specifies a Boolean SQL expression; multiple conditions joined with AND/OR are supported. When a task is triggered (based on its SCHEDULE or AFTER setting), it validates the conditions of the expression to determine whether to execute. If the conditions of the expression are not met, then the task skips the current run. Any tasks that identify this task as a predecessor also don’t run.
	// Specifies a Boolean SQL expression; multiple conditions joined with AND/OR are supported. When a task is triggered (based on its SCHEDULE or AFTER setting), it validates the conditions of the expression to determine whether to execute. If the conditions of the expression are not met, then the task skips the current run. Any tasks that identify this task as a predecessor also don’t run.
	// +kubebuilder:validation:Optional
	When *string `json:"when,omitempty" tf:"when,omitempty"`
}

type TaskRelationsInitParameters struct {
}

type TaskRelationsObservation struct {

	// (String)
	FinalizedRootTask *string `json:"finalizedRootTask,omitempty" tf:"finalized_root_task,omitempty"`

	// (String)
	Finalizer *string `json:"finalizer,omitempty" tf:"finalizer,omitempty"`

	// (Set of String)
	Predecessors []*string `json:"predecessors,omitempty" tf:"predecessors,omitempty"`
}

type TaskRelationsParameters struct {
}

type TimeInputFormatInitParameters struct {
}

type TimeInputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimeInputFormatParameters struct {
}

type TimeOutputFormatInitParameters struct {
}

type TimeOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimeOutputFormatParameters struct {
}

type TimestampDayIsAlways24HInitParameters struct {
}

type TimestampDayIsAlways24HObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimestampDayIsAlways24HParameters struct {
}

type TimestampInputFormatInitParameters struct {
}

type TimestampInputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimestampInputFormatParameters struct {
}

type TimestampLtzOutputFormatInitParameters struct {
}

type TimestampLtzOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimestampLtzOutputFormatParameters struct {
}

type TimestampNtzOutputFormatInitParameters struct {
}

type TimestampNtzOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimestampNtzOutputFormatParameters struct {
}

type TimestampOutputFormatInitParameters struct {
}

type TimestampOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimestampOutputFormatParameters struct {
}

type TimestampTypeMappingInitParameters struct {
}

type TimestampTypeMappingObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimestampTypeMappingParameters struct {
}

type TimestampTzOutputFormatInitParameters struct {
}

type TimestampTzOutputFormatObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimestampTzOutputFormatParameters struct {
}

type TimezoneInitParameters struct {
}

type TimezoneObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TimezoneParameters struct {
}

type TraceLevelInitParameters struct {
}

type TraceLevelObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TraceLevelParameters struct {
}

type TransactionAbortOnErrorInitParameters struct {
}

type TransactionAbortOnErrorObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TransactionAbortOnErrorParameters struct {
}

type TransactionDefaultIsolationLevelInitParameters struct {
}

type TransactionDefaultIsolationLevelObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TransactionDefaultIsolationLevelParameters struct {
}

type TwoDigitCenturyStartInitParameters struct {
}

type TwoDigitCenturyStartObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type TwoDigitCenturyStartParameters struct {
}

type UnsupportedDdlActionInitParameters struct {
}

type UnsupportedDdlActionObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type UnsupportedDdlActionParameters struct {
}

type UseCachedResultInitParameters struct {
}

type UseCachedResultObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type UseCachedResultParameters struct {
}

type UserTaskManagedInitialWarehouseSizeInitParameters struct {
}

type UserTaskManagedInitialWarehouseSizeObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type UserTaskManagedInitialWarehouseSizeParameters struct {
}

type UserTaskMinimumTriggerIntervalInSecondsInitParameters struct {
}

type UserTaskMinimumTriggerIntervalInSecondsObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type UserTaskMinimumTriggerIntervalInSecondsParameters struct {
}

type UserTaskTimeoutMsInitParameters struct {
}

type UserTaskTimeoutMsObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type UserTaskTimeoutMsParameters struct {
}

type WeekOfYearPolicyInitParameters struct {
}

type WeekOfYearPolicyObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type WeekOfYearPolicyParameters struct {
}

type WeekStartInitParameters struct {
}

type WeekStartObservation struct {

	// (String)
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// (String)
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (String)
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String)
	Level *string `json:"level,omitempty" tf:"level,omitempty"`

	// (String)
	Value *string `json:"value,omitempty" tf:"value,omitempty"`
}

type WeekStartParameters struct {
}

// TaskSpec defines the desired state of Task
type TaskSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     TaskParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider TaskInitParameters `json:"initProvider,omitempty"`
}

// TaskStatus defines the observed state of Task.
type TaskStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        TaskObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// Task is the Schema for the Tasks API. Resource used to manage task objects. For more information, check task documentation https://docs.snowflake.com/en/user-guide/tasks-intro.
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,snowflake}
type Task struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.database) || (has(self.initProvider) && has(self.initProvider.database))",message="spec.forProvider.database is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.name) || (has(self.initProvider) && has(self.initProvider.name))",message="spec.forProvider.name is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.schema) || (has(self.initProvider) && has(self.initProvider.schema))",message="spec.forProvider.schema is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.sqlStatement) || (has(self.initProvider) && has(self.initProvider.sqlStatement))",message="spec.forProvider.sqlStatement is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.started) || (has(self.initProvider) && has(self.initProvider.started))",message="spec.forProvider.started is a required parameter"
	Spec   TaskSpec   `json:"spec"`
	Status TaskStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// TaskList contains a list of Tasks
type TaskList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Task `json:"items"`
}

// Repository type metadata.
var (
	Task_Kind             = "Task"
	Task_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Task_Kind}.String()
	Task_KindAPIVersion   = Task_Kind + "." + CRDGroupVersion.String()
	Task_GroupVersionKind = CRDGroupVersion.WithKind(Task_Kind)
)

func init() {
	SchemeBuilder.Register(&Task{}, &TaskList{})
}
